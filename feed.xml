<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://sukwonyun.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sukwonyun.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-12-24T12:36:04+00:00</updated><id>https://sukwonyun.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">[그래프] Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View</title><link href="https://sukwonyun.github.io/blog/2022/MAD/" rel="alternate" type="text/html" title="[그래프] Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View" /><published>2022-06-08T16:37:28+00:00</published><updated>2022-06-08T16:37:28+00:00</updated><id>https://sukwonyun.github.io/blog/2022/MAD</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2022/MAD/"><![CDATA[<h1 id="mad">MAD</h1>

<h2 id="1-problem-definition"><strong>1. Problem Definition</strong></h2>

<blockquote>
  <p>What is Over-smoothing?</p>
</blockquote>

<p>최근 GNN의 발전으로 그래프 기반 여러 문제들을 푸는데 많은 발전이 있었다. 하지만, 이러한 성공에도 불구하고 간과되는 점이 있다. 바로 <code class="language-plaintext highlighter-rouge">Over-smoothing</code> 이슈다. 여기서 Over-smoothing 이라는 것은, 단어에서 우리가 유추할 수 있듯, 과하게 smoothing이 일어난다는 것이다. 먼저 GNN이 현재까지 성공을 거둔 이유는 그래프 자료구조의 특성인 자기와 비슷한 노드는 서로 앳지로 연결되어있는 이러한 상황을 이주 잘 utilize 한데 있었다. 여기서 자기와 비슷한 노드끼리 연결되어 있는 상황을 우리는 homophily 특성에 대응시킬 수 있고 동시에 이를 smoothness 한 상황이라고 볼 수 있다. 즉, 이러한 smoothness가 적절한 수의 layer를 바탕으로 했을 땐 장점으로 작용하지만 되려 layer를 과도하게 쌓게되면 서로서로 representation이 다 비슷해져서 다른 라벨을 가진 노드끼리 식별성이 떨어지는 그런 상황이 바로 <strong>Over-smoothing</strong> 한 상황이라고 해석할 수 있다. 즉, <code class="language-plaintext highlighter-rouge">과유불급</code>이 정확히 부합하는 상황이다.</p>

<p>먼저, 시각적으로 이 상황을 이해해 볼 필요가 있다. 아래 첫번째 그림은 Input Graph와 node1, node2, node3, node4에 대한 1-hop neighbor 를 표현한 그림이다. 이때는 node1(노란색), node4(보라색)를 center로 한 그래프가 많이 다른 모습을 볼 수 있다. 이에 자기자신과 비슷한 node 에서 더욱 많은 정보들을 받으며 embedding을 업데이트 할 수 있다. 다만,두번째 그림에서는 상황이 달라진다. 첫번째 그림과 달리 node1(노란색), node4(보라색)를 center로 한 그래프가 많이 비슷한, 즉 공유하고 있는 노드들이 많이 겹치는 모습을 볼 수 있다. 이런 식으로, layer 을 더 쌓을수록 더 많은 노드들을 서로 공유하게 되어 최종 업데이트 된 embedding이 서로서로 비슷하지게 된다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895636-9dd006fd-b664-4afe-9461-867af061947a.png" width="400" height="200" /></center>
<center><img src="https://user-images.githubusercontent.com/68312164/174895639-1b36d699-c7d6-4426-991e-a958dcbf9a37.png" width="400" height="200" /></center>

<p>정리하면, Over-smoothing 이 발생하는 상황을 우리는 현재 집중하고 있고 node들의 class를 구분하는 <em>node classification</em> 등의 task 에서 이는 심각한 문제가 되고 따라서 이를 개선할 필요성이 대두된다. 하지만, 현재 많은 연구들이 GNN의 모델링, 효과적인 알고리듬 구축에 신경을 쓰고 있을 뿐, Over-smoothing의 문제를 타겟하고 이를 해결하기 위한 연구는 더딘 상태이다. 그래서 오늘의 Paper는 다음 3가지의 문제에 접근하고자 한다.</p>

<ol>
  <li><strong>Systematic and Quantitative study of over-smoothing issue and verification of key factor that cause over-smoothing</strong>
    <ul>
      <li>먼저, Over-smoothing이 발생하는 상황에 대한 이해 그리고 무엇보다 이를 <strong>정량화</strong>하기 위해 Smoothness 그리고 Oversmoothness의 <code class="language-plaintext highlighter-rouge">척도(measure)</code>를 제시하고 동시에 Over-smoothing을 일으키는 핵심원인을 살펴본다.</li>
    </ul>
  </li>
  <li><strong>Two Quantitative metrics: MAD, MADGap</strong>
    <ul>
      <li>Smoothness 를 정량화하기 위한 척도로 <code class="language-plaintext highlighter-rouge">MAD(Mean Average Distance)</code> 그리고 Over-smoothness를 정량화하기 위한 척도로 <code class="language-plaintext highlighter-rouge">MADGap(Mean Average Distance Gap)</code>을 제시한다.</li>
    </ul>
  </li>
  <li><strong>Two methods: MADReg, AdaEdge</strong>
    <ul>
      <li>척도와 더불어, 실제로 Oversmoothing을 방지할 수 있는 2가지의 방법론 MADReg(MADGap-based Regularizer) 그리고 AdaEdge(Adaptive Edge Optimization)을 제시한다.</li>
    </ul>
  </li>
</ol>

<h2 id="2-motivation"><strong>2. Motivation</strong></h2>

<blockquote>
  <p>How to measure Over-smoothing? MADGap!</p>
</blockquote>

<p>앞서 우리는 GNN에서 Over-smoothing이 문제가 되는 상황을 살펴보았다. 궁극적으로, 문제를 발견하고 이를 해결해야할텐데 그렇다면 여기서 자연스럽게 Motivation이 발생하게 된다. 바로 문제가 되는 <code class="language-plaintext highlighter-rouge">Over-smoothing을 정량화할 수 있냐</code>는 물음에 대한 답이다. 정량화할 수 있게 된다면 이를 수치적으로 바라볼 수 있게 되고 더욱 구체화하면, <strong>언제 어떻게 어느정도로</strong> 심화되는지 한 층더 심화해서 살펴볼 수 있게 된다.</p>

<h3 id="1-mad">(1) MAD</h3>

<p>먼저 Smoothness, 그리고 Over-smoothness 두 상황을 구분해서 바라봐야할텐데 Smoothness를 먼저 정량화해보자. 이해를 돕기 위해 직접 수식과 함께 Matrix를 그려보면 아래와 같이 나타낼 수 있다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895627-9155eb8f-f410-4ad0-ba9b-afa72fd5a486.png" width="600" height="300" /></center>

<p>수식 순서대로 설명을 해보면 아래와 같다.</p>

<p><strong>(1)</strong> 임베딩 matrix를 토대로 모든 노드 페어 간 cosine similaritiy를 구한 뒤 이를 1에서 빼주어 cosine distance matrix, <img src="https://latex.codecogs.com/svg.image?D" alt="" />를 정의해준다. 여기서 1에서 빼주는 이유는, 우리는 similarity가 아닌 distance로 접근하고 있기 때문이다. (즉, 두 노드 간 similairity가 높을수록 거리는 가깝기 때문)</p>

<p><strong>(2)</strong> 이후, mask matrix, <img src="https://latex.codecogs.com/svg.image?M%5E%7Btgt%7D" alt="" />와 element-wise 하게 곱하여 내가 원하는 노드 페어만을 살펴볼 수 있게 target matrix, <img src="https://latex.codecogs.com/svg.image?D%5E%7Btgt%7D" alt="" />를 구한다. 이때 target matrix는 우리가 원하는 노드 페어 (i,j) 는 1의 값을 갖고 나머지 페어는 0의 값을 가진다.</p>

<p><strong>(3)</strong> <strong>행 단위</strong>로 normalize 해주어 <code class="language-plaintext highlighter-rouge">행렬을 벡터로</code> 축소한다. 이 때, 값이 존재하는 페어의 값은 1로 취급해주어 normalize 해준다.</p>

<p><strong>(4)</strong> <strong>열 단위</strong>로 normalize 해주어 <code class="language-plaintext highlighter-rouge">벡터를 스칼라로</code> 축소한다. 이 때, 값이 존재하는 페어의 값은 1로 취급해주어 normalize 해준다. 그리고 최종적으로, 사전에 살정한 target 노드 페어를 바탕으로 한 <img src="https://latex.codecogs.com/svg.image?MAD%5E%7Btgt%7D" alt="" /> 을 얻는다.</p>

<p>이렇게 정의된 MAD 값이 정말 유의미한지 우리는 verify 해 볼 필요가 있다. 이에 대한 검증으로 paper는 아래 Figure 를 제시한다. 이를 통해, 우리는 여러 GNN 모델에서 Layer를 깊게 쌓을수록 MAD값이 줄어드는 상황, 즉 노드 페어 간 Mean Average Distance, 거리가 감소하는 상황을 살펴볼 수 있다. 여기서 거리가 감소한다는 것은 서로 가까이 위치한, 즉 서로서로 표현이 비슷한 상황이다. 여기서 더 쉬운 이해를 위해 MAD는 <code class="language-plaintext highlighter-rouge">식별성</code>에 대응시키면 쉽게 이해할 수 있다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895628-0b5f8731-39a5-4daa-9f28-1865b68f63f9.png" width="500" height="300" /></center>

<h3 id="2-information-to-noise-ratio">(2) Information-to-noise Ratio</h3>

<p>이로써 우리는 그래프의 임베딩 표현을 바탕으로 smoothness를 정량화할 수 있는 척도를 얻어냈다. 하지만 우리는 본래 목표했던 Over-smoothing 에 대해 더 이해해 볼 필요가 있다. Paper 는 Over-smoothing 의 원인을 <code class="language-plaintext highlighter-rouge">over-mixing of information and noise</code> 때문이라고 보고 있다. 즉, smoothness 를 토대로 장점을 얻지만 동시에 이 smoothness 때문에 되려 noise 가 발생할 수 있다는 것이고 이 noise 의 영향력이 커져 Over-smoothing이 일어난다는 것이다. 동시에 또, 현재까지 GNN이 성공적이었던 이유는 information의 비율이 noise의 비율보다 컸기 때문이라고 논문은 주장한다. 여기서 구체화해보면, _information_은 <strong>intra-class</strong> (같은 클래스 내) 그리고 _noise_는 <strong>inter-class</strong> (다른 클래스 간)로 이해할 수 있다.</p>

<p>이러한 information 그리고 noise가 공존하는 상황을 역시 비율로써 정량화할 수 있는데 이를 정리해보면 아래와 같다. <code class="language-plaintext highlighter-rouge">Information-to-noise</code> 는 전체 노드 페어 중에서 intra-class(같은 클래스 간 연결된 페어)의 비율로 나타낼 수 있고, 예를 들어 2-hop 내에서 Information-to-noise 를 노드 관점, 그리고 그래프 관점에서 각각 구할 수 있다. 둘의 차이는 노드 관점에서는 2-hop내 실제 노드 수를 바탕으로 한다는 점과 그래프 관점에서는 2-hop내 실제 노드 페어 수를 바탕으로 한다는 점이다. 역시 정량화한 Information-to-noise가 유의미한지 확인해볼 필요가 있다. 오른쪽 그림을 보면, Order(Hop)가 높아질수록, Information-to-noise 비율이 급격하게 줄어드는 경향성을 확인할 수 있다. 이를 통해, 우리는 Hop 이 커질수록, intra-class 가 줄어들고(i.e., inter-class 는 늘어남) information에 비해 noise가 더욱 커지는 상황을 확인할 수 있다. 종합하면, 우리는 Over-smoothing의 원인을 <strong>over-mixing of information and noise</strong> 바라보았고 이는 information-to-noise 의 비율로서 살펴볼 수 있었고, 결과적으로 Hop이 커질수록 noise가 커지는 상황을 재차 확인하였다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895622-9801a781-7336-411e-8226-eb7c059f937e.png" width="630" height="300" /></center>

<h3 id="3-madgap">(3) MADGap</h3>

<p>이렇게 Hop(i.e., Order)이 커질수록 noise가 커지는 상황을 우리는 두 가지 케이스로 구분하여 바라보려고 한다. 바로 order가 작은 상황(i.e., neighboring nodes, 논문에서는 3-hop 이내) 그리고 order가 큰 상황(i.e., remote nodes, 논문에서는 8-hop 이상)이다. 아래 정리된 그림을 통해 보면, <img src="https://latex.codecogs.com/svg.image?MADGap" alt="" />은 멀리 떨어졌을 때의 식별성, <img src="https://latex.codecogs.com/svg.image?MAD%5E%7Brmt%7D" alt="" />과 가까이 있을 때의 식별성, <img src="https://latex.codecogs.com/svg.image?MAD%5E%7Bneb%7D" alt="" />의 차를 통해 정의되는 것을 확인할 수 있고 이를 통해 우리는 드디어 <code class="language-plaintext highlighter-rouge">Over-smoothing 이 언제 발생하는지</code>, 이를 <code class="language-plaintext highlighter-rouge">수치적으로</code> 이해할 수 있게된다. 즉, <img src="https://latex.codecogs.com/svg.image?MADGap" alt="" />이 크면 그만큼 멀리 떨어진 노드의 식별성이 좋은 상황이므로, 우리에게 좋은 상황이되고 이와 달리 <img src="https://latex.codecogs.com/svg.image?MADGap" alt="" />이 작거나 음수 값을 가지게 되면 멀리 떨어진 노드들의 식별성이 가까운 노드들보다 안좋은, 바로 <strong>Over-smoothing</strong> 이 발생하는 순간임을 알 수 있다.</p>

<p>정의한 MADGap이 실제로 Over-Smoothing을 잘 대변하는 효과적인 수치인지 역시 확인해 볼 필요가 있다. 저자는 아래 실험들을 통해 효과성을 검증한다. 해석해보면, 많은 경우 MADGap과 Accuracy가 같은 경향성을 가지고 있고 실제로 Pearson 계수까지 1에 가까운 수치를 가지고 있음을 확인할 수 있다. 이를 통해, 우리는 Layer가 커질수록 감소하는 Accuracy 와 같은 경향을 지닌 MADGap이 Measure로서 타당함을 확인할 수 있다. 첨언하면, MADGap 이 감소한다는 것은 멀리 떨어진 노드의 식별성이 떨어져서 Over-smoothing 이 발생하고 있다는 것이다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895634-10ea8e19-e7f9-4182-a4dc-956d8cd401d9.png" width="650" height="300" /></center>

<h3 id="4-topology-affects-the-information-to-noise-ratio">(4) Topology Affects the Information-to-noise Ratio</h3>

<p>앞서 우리는 Oversmoothing 의 원인이 되는 Information-to-noise를 살펴봤고 이를 통해 MADGap을 정의할 수 있었다. 그러면 이러한 Information-to-noise에 영향을 주는 요소를 찾아 볼 필요성이 대두된다. 결론부터 말하면, 바로 Edge를 기반으로 Graph가 생성되는 방식, <code class="language-plaintext highlighter-rouge">Graph topology</code> 때문이라고 paper는 주장한다. 이는 Graph가 생성된 방식과 우리가 풀고자 하는 문제(e.g., node classification)에서 괴리가 있다는 것인데, 더 구체화하면 node classification에서는 서로 다른 클래스의 노드들을 잘 구분하는게 목표임에 비해, 그래프가 애초에 생성될 때 <strong>inter-class</strong>의 Edge가 너무 많다는 것이다. 이러한, 서로 다른 클래스를 연결해주는 inter-class의 엣지는 message-passing 과정에서 자기 자신 뿐만이 아닌 다른 클래스의 정보도 전파해서 악영향을 끼치게 된다. 여기서 우리는 intra-class의 엣지는 늘려주고, inter-class의 엣지는 제거해주면 우리가 풀고자 하는 문제에 더 적합할 것이라는 Motivation을 얻게 된다. 실제로 저자는 간단한 실험을 통해 이를 입증하는데, 아래 그림에서 <em>inter-class의 엣지를 제거할수록</em>, 그리고 <em>intra-class의 엣지를 증가시킬수록</em> 더욱 성능 개선이 있음을 Acc, MAGap 측면에서 확인할 수 있다.</p>

<center><img src="https://user-images.githubusercontent.com/68312164/174895640-959492aa-0a73-4312-b3dd-471155dbbd0b.png" width="650" height="300" /></center>

<h2 id="3-method"><strong>3. Method</strong></h2>

<blockquote>
  <p>Let’s alleviate Over-smoothing!</p>
</blockquote>

<p>앞선 Motivation에서 우리는 3가지의 새로운 척도인 MAD, Information-to-noise, MADGap를 도입하여서 Smoothness 그리고 Over-smoothness를 수치적으로 정량화하였다. 그렇다면 이렇게 정의한 Over-smoothing을 실제로 개선하기 위해서는 어떻게 접근해야할까? Paper는 두 가지 간단한 방안을 제시한다.</p>

<h3 id="1-madreg-madgap-as-regularizer">(1) <strong>MADReg: MADGap as Regularizer</strong></h3>

<p>필자는 여기서 앞서 정의한 척도, <code class="language-plaintext highlighter-rouge">MADGap</code>이 비로소 빛이 난다고 생각한다. 바로, 우리가 minimize하고 싶은 loss에 추가적인 텀으로, regularizer로 붙여주기만 하면 되기 때문이다. 먼저 식을 살펴보자.</p>

\[\begin{equation} \mathcal{L} = \sum -l\text{log} p(\hat{l}|\mathbf{X},\mathbf{A},\mathbf{\Theta}) - \lambda \text{MADGap} \end{equation}\]

<p>기본적인 Cross-Entropy loss 에 추가적으로 MADGap의 Regularizer가 추가되었다. 해석해보면, MADGap이 커질수록 remote nodes의 식별성이 커져서 우리에게 좋은 상황이고, MADGap이 작아질수록 remote nodes의 식별성이 작아지는, 우리에게 안좋은 상황이므로 임베딩이 업데이트되는 과정에서 전체 Loss를 줄이기 위해, MADGap이 커지도록 업데이트가 될 것이다. 또 다른 관점에서는 위에서 Accuarcy와 경향성이 일치하는 면모를 보았기에 이 Accuracy가 커지는 방향으로 업데이트 된다고 생각할 수도 있겠다. 추가적으로, <img src="https://latex.codecogs.com/svg.image?%5Clambda" alt="" />는 MADReg을 조절해주는 constant이다. 종합하면 아주 간단하지만, 위에서 정의한 MAD, MADGap 덕분에 이렇게 간다하면서도 효과적인 방안이 디자인될 수 있었다고 필자는 생각한다.</p>

<h3 id="2-adaedge-adaptive-edge-optimization">(2) <strong>AdaEdge: Adaptive Edge Optimization</strong></h3>

<p>또 다른 방안으로는, 우리가 앞서 살펴보았던 Motivation (2)-4 <code class="language-plaintext highlighter-rouge">Topology Affects the Information-to-noise Ratio</code>에서 비롯된다. 바로, inter-class의 엣지는 제거해주고 intra-class의 엣지는 증가시켜주는 방향으로 그래프의 구조를 다시 바꿔주는 방향으로 Optimization 되는 것이다. Optimization 알고리듬을 살펴보면 아래와 같다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174895641-5c0ee713-1726-416e-a1ff-a7f0c3cad2e4.png" width="650" height="270" /></center>

<p>간단히 살펴보면, ADDEDGE 함수에서는 실제 연결이 안되어있는 노드 페어를 대상으로 최종 prediction이 같고, softmax를 태운 결과값이 사전에 정의한 conf+ 의 값보다 크면 해당 페어를 기존 엣지에 추가적으로 연결해주는 역할을 하고 비슷하게 REMOVEDGE 함수는 실제 연결이 되어있는 노드 페어를 대상으로 서로 prediction이 다르고 softmax를 태운 결과값이 사전에 정의한 conf- 의 값보다 크면 해당 노드 페어의 엣지를 제거해주는 역할을 한다. 이 두함수를 바탕으로 매 iteration에서 Graph의 구조는 바뀌어가게된다.</p>

<h2 id="4-experiment"><strong>4. Experiment</strong></h2>

<p>다음은 위의 2가지 방안, MADReg 그리고 AdaEdge의 효과성을 입증하기 위한 실험이다. 실험은 node-classification을 대상으로 진행하였고 특정 방식의 GNN 모델링 혹은 알고리듬을 제안한게 아닌 각 GNN 모델에서 적용가능한, _Oversmoothing을 개선하는 하나의 Framework_를 제안하였기에 각 모델에 이를 적용해서 효과성을 입증하는 방식으로 실험이 진행되었다.</p>

<h3 id="experiment-setup"><strong>Experiment setup</strong></h3>

<ul>
  <li>Dataset
    <ul>
      <li>총 7가지의 dataset, _Cora, CiteSeer, PubMed, Amazon Photo, Amazon Computers, Coauthor CS, Coauthor Physics_를 사용하였다. Dataset의 Statistics는 아래와 같이 요약된다.</li>
    </ul>
    <center><img src="https://user-images.githubusercontent.com/68312164/174895615-50588735-4bb4-43a0-9267-6e5cbc7196fc.png" width="630" height="300" /></center>
  </li>
  <li>baseline
    <ul>
      <li>총 10가지의 GNN 베이스라인을 사용하였다. 가장 유명한 GCN부터 출발해서 ChebGCN, HyperGraph, FeatSt, GraphSAGE, GAT, ARMA, HighOrder, DNA, GGNN의 여러 GNN Variant를 다루었다.</li>
    </ul>
  </li>
  <li>Evaluation Metric
    <ul>
      <li>Accuracy와 해당 paper에서 제시한 MADGap 을 사용하였다.</li>
    </ul>
  </li>
</ul>

<h3 id="result"><strong>Result</strong></h3>

<p><strong>(1) MADReg and AdaEdge Results on <em>CORA/CiteSeer/PubMed</em></strong></p>

<center><img src="https://user-images.githubusercontent.com/68312164/174895618-18f8dffa-8209-4844-8c76-ec285b8c7ed2.png" width="630" height="300" /></center>

<p>일반적으로 GNN은 2-3 layer 내에서 Best Performace가 나오지만 그 이후 layer 수에서는 performance가 급격하게 감소하게 된다. 이에 저자는 4 layer를 기준으로 삼고 기존 baseline과 baseline에 MADReg 그리고 AdaEdge를 적용해 본 버전을 실험군으로 두었다. 결과를 확인해보면 Acc, MADGap 모두에서 그리고 Cora, CiteSeer, PubMed 데이터에서 Oversmoothing을 개선한 방안인 두 방법론이 효과적임을 확인할 수 있다. 실험은 5개의 split 방법에서 각각 10개의 random seed를 두어 진행하였기에 그려진 box plot이 유의미하다고 볼 수 있다.</p>

<p><strong>(2) MADReg with different layers and AdaEdge with GNN varaints</strong></p>

<center><img src="https://user-images.githubusercontent.com/68312164/174895621-046bfdaf-681f-49a9-a748-96edd71c8d5e.png" width="630" height="300" /></center>

<p>위에는 MADReg을 GCN에 적용하여서 Acc, MADGap 측면에서 기존 GCN과 대비하여 성능향상이 얼마나 있었는지 살펴본 결과이다. 확실하게 Layer를 많이 쌓을수록 기존 GCN의 성능은 급격하게 떨어지는 면모를 살펴볼 수 있는데 비해 MADReg을 적용한 버전은 상대적으로 그 성능이 떨어지는 기울기가 덜 급격한 것을 확인할 수 있다. 이는 Oversmoothing이 상대적으로 덜 일어나고 있음을 확인할 수 있는 대목이다.</p>

<p>밑에는 여러 GNN varaints에 AdaEdge 방법론을 적용했을 때 성능 증가폭을 살펴 본 결과이다. 확실하게 특정 GNN이 아닌 모든 GNN에서 효과적으로 적용가능한 framework임을 확인할 수 있는 실험으로 해석된다.</p>

<h2 id="5-conclusion"><strong>5. Conclusion</strong></h2>

<p>이로써 우리는 Oversmoothing이 일어나는 원인을 밝히고 이를 수치적으로 정량화할 수 있는 Measure들인 MAD, Information-to-noise Ratio, MADGap를 처음으로 살펴보았다. 더 나아가, Oversmoothing을 해결하기 위한 방법론으로 MADReg 그리고 AdaEDGE까지 살펴보고 그 방법론의 효과성까지 검증할 수 있다. 오늘의 논문을 세 줄 요약하면 다음과 같다.</p>

<ul>
  <li>(1) GNN에서 Oversmoothing을 파헤치고 왜 일어나는지 분석한 초창기 연구</li>
  <li>(2) MAD(for smoothness), Information-to-noise(key factor of oversmoothing), MADGap(for oversmoothness)</li>
  <li>(3) Oversmoothing을 해결하고자 한 MADReg, AdaEdge</li>
</ul>

<p>그리고, 필자는 이렇게 글을 마무리 짓고 싶다.</p>

<p><strong><code class="language-plaintext highlighter-rouge">Alleviating Oversmooting? Okay, but still it ain't guarantees best performance.</code></strong></p>

<h2 id="author-information"><strong>Author Information</strong></h2>

<ul>
  <li>Sukwon Yun (윤석원)
    <ul>
      <li>Master Student in ISySE, KAIST (<a href="http://dsail.kaist.ac.kr">DSAIL</a>)</li>
      <li>Interested in <strong>Weakness of GNN such as Long-Tail Problem, Over-smoothing Problem and Differential Equations on general NN</strong></li>
      <li>Contact: swyun@kaist.ac.kr</li>
    </ul>
  </li>
</ul>

<h2 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h2>

<ul>
  <li>Paper: <a href="https://arxiv.org/abs/1909.03211">https://arxiv.org/abs/1909.03211</a></li>
  <li>GCN: <a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a>
    <ul>
      <li>PDF 자료: <a href="https://github.com/SukwonYun/GNN-Papers">https://github.com/SukwonYun/GNN-Papers</a></li>
      <li>윤훈상 연구원님 자료: <a href="https://www.youtube.com/watch?v=F-JPKccMP7k\&amp;t=635s">https://www.youtube.com/watch?v=F-JPKccMP7k\&amp;t=635s</a></li>
    </ul>
  </li>
  <li>Github Review (본문 사진이 잘 안보일 경우): <a href="https://github.com/SukwonYun/awesome-reviews-kaist/blob/2022-Spring/paper-review/2022-spring/AAAI-2020-MAD.md">https://github.com/SukwonYun/awesome-reviews-kaist/blob/2022-Spring/paper-review/2022-spring/AAAI-2020-MAD.md</a></li>
</ul>]]></content><author><name></name></author><category term="그래프" /><category term="paper-review" /><summary type="html"><![CDATA[Deli Chen, Yankai Lim, Wei Li, Peng Li, Jie Zhou, Xu Sum / Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View / AAAI-2020]]></summary></entry><entry><title type="html">[그래프] Graph Neural Ordinary Differential Equations</title><link href="https://sukwonyun.github.io/blog/2022/GDE/" rel="alternate" type="text/html" title="[그래프] Graph Neural Ordinary Differential Equations" /><published>2022-04-25T16:37:28+00:00</published><updated>2022-04-25T16:37:28+00:00</updated><id>https://sukwonyun.github.io/blog/2022/GDE</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2022/GDE/"><![CDATA[<h1 id="gde">GDE</h1>

<h2 id="1-problem-definition"><strong>1. Problem Definition</strong></h2>

<blockquote>
  <p>Appropriate Relational Inductive Bias on GNN in terms of Continuous Domain !</p>
</blockquote>

<p>적절한 <code class="language-plaintext highlighter-rouge">Inductive Bias</code> 를 부여하는 것은 딥러닝 모델에서 아주 중요한 요소로 부각된다. 이때, 우리는 Inductive bias가 무엇인지 조금 더 엄밀하게 짚고 넘어가야할 필요가 있다. Inductive Bias는 모델이 unseen data에 대해서 더욱 잘 예측하기 위해 우리가 도입하는 <em>추가적인 가정</em> 으로 이해하면 좋다. 이 중에서도 Relational Inductive Bias는 이름 그대로 모델을 이루는 entities 간의 relationship 에 대해 우리가 부여하는 추가적인 가정으로 이해할 수 있다. 대표적으로, MLP와 CNN을 비교해보면, MLP는 하나의 인풋이 모든 아웃풋에 관여하지만 인풋 간의 관계성은 등한시되는 반면 CNN은 convolution filter가 window sliding을 하며 업데이트를 이어나가게 되고 이를 바탕으로 local한 인풋은 서로 weight sharing을 하는, 서로 관계가 비슷할 것이라는 가정이 들어가게 된다. 즉, Relational Inductive Biase 측면에서 MLP는 Weak한 반면 CNN은 Local내에서 Strong하다고 볼 수 있다. 이 관점에서, <strong>Relational Inductive Bias</strong>는 <strong>Weight Sharing</strong>과 대응되는 개념으로 바라볼 수 있게 된다.</p>

<p>그렇다면, 이제 본론으로 넘어와서 우리가 현재 포커싱하고 있는 <code class="language-plaintext highlighter-rouge">Graph Neural Network</code> 관점에서 바라보면 어떠한가? GNN은 node와 edge를 바탕으로 한 그래프 자료구조에서 딥러닝을 접목시켰기 때문에 Relation은 직관적으로 edge를 바탕으로 이뤄지고 있음을 알 수 있다. 이때, Relational Inductive Bias는 정형화되지 않은, arbitrary한 특성을 가지고 있다. 이는 GNN에서는 특정 두 노드를 기준으로 엣지가 정의되고 있는 본질적인 성질 때문이다. 예를 들어보자면, 전 세계 대학원생의 그래프를 만들어본다고 했을 때, 각 국가를 라벨로 가지고 노드는 해당 대학원생의 특성으로 정의된다고 해보자. 이때, 두 대학원생을 이어주는 엣지는 취미생활이 같은 경우(e.g., 축구)라고 하면 한국 내에서 대학원생 김 모군 - 박 모군 의 관계도 있을 것이고 미국에서 John - Andrew 의 관계도 있을 것이다. 두 Pair(김-박, John-Andrew)는 그래프 내에서 local하지는 않아도 관계는 일치하기 때문에 비슷한 weight를 share할 가능성도 크다. 이러한 경우가 바로 aribitrary한 Relational Inductive Bias를 갖는 경우로 볼 수 있다. 앞선 두 문단을 하나의 사진으로 요약하면 아래와 같다.</p>

<center><img src="https://user-images.githubusercontent.com/68312164/174891532-03f87ad7-898b-4c18-b0fa-f0f66cd36f54.png" width="600" height="300" /></center>

<p>우리가 오늘 특히 집중할 Inductive Bias는 시스템 내 데이터를 바탕으로 한 <code class="language-plaintext highlighter-rouge">Temporal Behavior</code>, 즉 시간에 따른 행동양상이다. 앞서 우리는 inductive bias를 <em>추가적인 가정</em> 에 대응되는 개념이라고 했다. 즉, 현재 경우에 접목시켜보면 우리의 추가적인 가정은, 시간에 변화 따라 시스템의 dynamics이 <strong>discrete</strong>한 지, <strong>continuous</strong>인지 등의 가정을 부여해줄 수 있다. 이 중, 특히 신경망을 연속적인 layer의 구조로 표현하는 관점 그리고 <em>상미분방정식(ODE)의 초기값 문제의 해</em> 를 통해 이를 업데이트 하는 과정은 최근 딥러닝 모델로 하여금 새로운 패러다임을 제안했다고 볼 수 있다.</p>

<p>이러한 흐름 즉, GNN관점에서 Temporal Behavior 측면 상 적절한 Inductive Bias를 부여하기 위해 해당 paper는 아래 3가지의 문제에 접근하고자 한다.</p>

<ol>
  <li><strong>Blending graphs and differential equtations</strong>
    <ul>
      <li>상미분방정식(ODE)을 GNN으로 parameterize하고 system-theoretic한 framework, <strong>Graph neural Ordinary Differential Euqations, GDE</strong>를 제안하고자 한다. 이때 GDE는 ODE를 바탕으로 한 연속적인 관점, 그리고 GNN의 본질적인 Reltaional Inductive bias를 내포한 체로 디자인된다는 특징점을 가진다. 이러한 GDE는 효과성은 semi-supervised의 node classification task와 spatio-temporal foecasting task에서 실험적으로 입증한다.</li>
    </ul>
  </li>
  <li><strong>Sequence of graphs</strong>
    <ul>
      <li>GDE의 framework를 spati-temporal 세팅으로 가저간 뒤, hybrid dynamical system관점에서 일반적인 autoregressive(자가회귀모형)으로 모델링한다. 이때, autoregressive GDE는 ODE의 적분 구간을 변경해줌으로써, irregular한 데이터 관측에서도 잘 대응할 수 있게 해준다.</li>
    </ul>
  </li>
  <li><strong>GDEs as general-purpose models</strong>
    <ul>
      <li>특히, GDE는 연속적인 환경에서 GDE를 효과적이게 모델링하기 위한 별도의 assumption, 가정이 불필요하다는 장점을 가진다. 즉, 범용적인 측면에서 높은 성능을 내고 효과적임을 실험적으로 입증한다.</li>
    </ul>
  </li>
</ol>

<h2 id="2-motivation"><strong>2. Motivation</strong></h2>

<blockquote>
  <p>GNN + Neural ODE = Continuous GNN !</p>
</blockquote>

<p>이 Paper에서 기존의 GNN이 가지는 discrete한 모델링의 한계를 극복하고자 한다. 즉, continuous한 <code class="language-plaintext highlighter-rouge">Graph Neural Network</code>을 모델링해보고자 함이다. 무엇을 통해? 바로 NeurIPS 2018 best paper로 선정된 <strong>Neural Ordinary Differential Equations</strong> 에서 제안된 신경망을 미분방정식의 해로 바라보는 관점을 통해. 앞선 두 문장에서 유추할 수 있듯, 우리는 두 가지 key concept을 먼저 이해하고 본격적인 GDE의 모델링 측면으로 넘어가고자 한다.</p>

<h3 id="1-graph-neural-network">(1) Graph Neural Network</h3>

<ul>
  <li>먼저, GNN을 이해할 필요가 있는데, 이 중 가장 대표적인 <code class="language-plaintext highlighter-rouge">GCN(Graph Convolutional Networks)</code>을 간단히 설명해보고자 한다. 기존의 딥러닝 분야(e.g., CNN)과 달리 GNN은 non-euclidean space에서 정의되고 feature들이 독립적이지 않다는 속성을 key motivation으로 삼아 발전한, Graph 자료구조에 신경망을 접목시킨 모델이라고 이해할 수 있다. 그 중, GCN은 이름에서 유추할 수 있듯, CNN에서의 Convolution 연산을 그래프 자료구조에 접목시킨 대표적인 모델이다. Graph에서 Convolution을 적용하기 위한 과정으로는 퓨리에 변환(Signal을 Frequency로 변환하는 과정)이 필수적으로 수반되게 되고 이때 우리는 Signal을 node의 label, Frequency를 중심노드와 이웃노드의 차이로 대응할 수 있게 된다. 핵심은, 우리는 이러한 중심노드와 이웃노드의 차이가 적기를 바라며, 이러한 <strong>이웃노드들로부터 자신의 노드를 업데이트하는 과정</strong> 이 바로 GCN의 본질이라는 것이다. 이에 대한 더욱 자세한 설명은 해당 페이지에서 GCN에 대한 PDF를 참고하면 도움이 된다. <a href="https://github.com/SukwonYun/GNN-Papers">https://github.com/SukwonYun/GNN-Papers</a></li>
</ul>

<center><img src="https://user-images.githubusercontent.com/68312164/174891529-fe078794-106b-45a4-a85f-554957103e89.png" width="600" height="300" /></center>

<ul>
  <li>수식을 통해 이해해보면 아래와 같이 설명할 수 있다. 이때, <img src="https://latex.codecogs.com/svg.image?%5Cmathbf%7Bh\_v%5E%7Bl%7D%7D" alt="" />은 <img src="https://latex.codecogs.com/svg.image?l" alt="" />번째 레이어에서 노드 <img src="https://latex.codecogs.com/svg.image?v" alt="" />의 hidden representation 이고 <img src="https://latex.codecogs.com/svg.image?%5Cmathcal%7BN%7D\_v" alt="" />는 노드 <img src="https://latex.codecogs.com/svg.image?v" alt="" />의 이웃노드들의 집합이다. 수식에서 보듯 자기자신의 representation을 업데이트하는 과정에서 이웃노드들의 representation을 바탕으로 한다는 것이 GNN의 핵심이다. GCN은 이 중에서도 Laplacian 연산(i.e.,<img src="https://latex.codecogs.com/svg.image?%5Cmathbf%7B%5Chat%7BD%7D%7D%5E%7B-1/2%7D%5Cmathbf%7B%5Chat%7BA%7D%7D%5Cmathbf%7B%5Chat%7BD%7D%7D%5E%7B-1/2%7D" alt="" />)을 통해 자기자신과 이웃노드들의 representation 평균 합으로 AGGREGATE하는 GNN으로 이해하면 된다. 이때, <img src="https://latex.codecogs.com/svg.image?%5Cmathbf%7BW%7D%5E%7B\(l-1\)%7D" alt="" />은 <img src="https://latex.codecogs.com/svg.image?l-1" alt="" />번 째 layer에서 업데이트 대상이 되는 파라미터이다.</li>
</ul>

\[\begin{equation} \mathbf{h}_{v}^{(l)}=\text{COMBINE}^{(l)}\left(\mathbf{h}_{v}^{(l-1)}, \text{AGGREGATE}^{(l-1)}\left(\left\{\mathbf{h}_{u}^{(l-1)}: u \in \mathcal{N}(v)\right\}\right)\right) \end{equation}\]

\[\begin{equation} \mathbf{H}^{(l)} = \sigma(\mathbf{\hat{D}}^{-1/2}\mathbf{\hat{A}}\mathbf{\hat{D}}^{-1/2}\mathbf{H}^{(l-1)}\mathbf{W}^{(l-1)}) \end{equation}\]

<h3 id="2-nerual-ode">(2) Nerual ODE</h3>

<ul>
  <li>2018년 발표된 Neural Ordinary Differential Equations는 <code class="language-plaintext highlighter-rouge">Neural Network를 Continuous Domain</code>에서 바라볼 수 있게 한, 새로운 패러다임을 제안한 논문으로 평가되고 있다. 사실 이 논문의 key contribution은 신경망을 미분방정식의 해로 표현하는 그 주춧돌 역할을 제안했다기 보다는, Backward pass를 adjoint sensitivity method를 도입하므로써 gradient를 아주 효과적으로 구할 수 있게 해준데 있다. 먼저, 어떻게 discrete했던 기존의 신경망을 continuous하게 바라볼 수 있게 되었는지 <code class="language-plaintext highlighter-rouge">ResNet</code>을 통해 간단히 intuition을 살펴보고자 한다. 핵심은 ResNet에서 비롯된 residual connection을 좌변으로 넘겨서 1이었던 변화량을 generalize하여 미분의 관점으로 바라보는 것이다. 이로써, discrete했던 layer의 index 혹은 timestamp, <img src="https://latex.codecogs.com/svg.image?t" alt="" />를 하나의 variable로 모델링할 수 있어진다. 이는 아래의 식과 같이 나타낼 수 있고 이러한 변화를 통해 Residual Network와 ODE Network의 Depth별 gradient의 흐름, hidden state의 업데이트 과정을 아래와 같이 이미지화 할 수 있다.</li>
</ul>

\[\begin{equation} \begin{aligned} \mathbf{h}_{t+1} = f(\mathbf{h}_{t}, \theta_t) + \mathbf{h}_{t} \\ \mathbf{h}_{t+1} - \mathbf{h}_{t} = f(\mathbf{h}_{t}, \theta_t) \\ \frac{\mathbf{h}_{t+\Delta} - \mathbf{h}_{t}}{\Delta}|_{\Delta=1} = f(\mathbf{h}_{t}, \theta_t) \\ \lim_{\Delta \rightarrow 0} \frac{\mathbf{h}_{t+\Delta} - \mathbf{h}_{t}}{\Delta} = f(\mathbf{h}_{t}, \theta_t) \\ \frac{d\mathbf{h}(t)}{dt} =f(\mathbf{h}(t),t,\theta) \\ \end{aligned} \end{equation}\]

<center><img src="https://user-images.githubusercontent.com/68312164/174891533-0285fb3f-1aae-4694-b1dd-cef5453082cd.png" width="550" height="300" /></center>

<ul>
  <li>
    <p>이러한 intuition을 바탕으로 2018년 Neural ODE는 Backward Pass에 <code class="language-plaintext highlighter-rouge">Adjoint Sensitivity Method</code>를 접목시켜서 parameter를 업데이트 시키는 과정에서 gradient를 훨씬 효과적으로 구해낼 수 있게 하였고 이는 연구자들로 하여금 새로운 출발점을 알린 획기적인 시점이 되었다. Forward Method와 대비되는 Adjoint Sensitivity Method는 과연 무엇인지 아래 슬라이드 두개로 대체하고자 한다. 간단히 요약하자면, 초기값 문제를 풀고 Loss를 정의하여 parameter를 업데이트하는 과정에서 time dependent solution function에 대한 parameter 변화량(i.e., <img src="https://latex.codecogs.com/svg.image?%5Cfrac%7Bd%5Ctextbf%7Bu%7D%7D%7Bd%5Cboldsymbol%7B%5Ctheta%7D%7D" alt="" />을 구해야하는데 이를 구하기가 상당히 수고스러운 일이었다. 이에 비해 Adjoint Sensitivity Method는 이를 직접적으로 구하지 않고 Optimization 문제로 치환하여 Lagrangian을 도입하고 앞선 변화량(i.e., <img src="https://latex.codecogs.com/svg.image?%5Cfrac%7Bd%5Ctextbf%7Bu%7D%7D%7Bd%5Cboldsymbol%7B%5Ctheta%7D%7D" alt="" />의 계수들을 0으로 만드는 별도의 초기값 문제를 하나 더 제안하여, 총 2개의 ODE를 푸는 것만으로 파라미터를 업데이트 하는 방법론이다.구체화 된 과정은 아래 슬라이드와 같이 나타낼 수 있다.
<img src="https://user-images.githubusercontent.com/68312164/174891526-1821cca7-6f6d-42f1-8f80-de16825d087f.png" width="340" height="250" /><img src="https://user-images.githubusercontent.com/68312164/174891467-258b42e8-b533-45a1-81b2-4ec54a41d46c.png" width="340" height="250" /></p>
  </li>
  <li>
    <p>이러한 Neural ODE는 기존의 딥러닝 모델과 같이 gradient를 직접적으로 구하는 것이 아닌 <code class="language-plaintext highlighter-rouge">gradient를 mimic하는 과정</code>으로 볼 수 있기에 별도의 gradient를 저장할 필요가 없어진다. 따라서, <strong>memory efficient</strong>하다는 장점, timestamp에 종속적이었던 시간 <img src="https://latex.codecogs.com/svg.image?t" alt="" />를 별도의 변수로 모델링하여 <strong>구간 내의 dynamics를 하나의 함수로 모델링</strong> 할 수 있다는 장점, <strong>irregular한 time에 대한 대응</strong>, 그 간 <strong>수리적으로 입증되었던 미분방정식 풀이법을 딥러닝에 접목</strong> 시킬 수 있다는 장점 등 다수의 매력을 내포한 체 딥러닝에 새로운 패러다임을 제안하게 되었다.</p>
  </li>
</ul>

<h2 id="3-method"><strong>3. Method</strong></h2>

<p>본격적으로 Method로 들어가고자 한다. 앞선 Motivation이 어느정도 구체적이었고 길었던 이유는 바로 오늘의 Graph neural ordinary Differential Euqations, GDE가 결과적으로 <code class="language-plaintext highlighter-rouge">GNN과 Neural ODE를 접목시킨 퍼스트 펭귄의 역할을 하는 paper</code>로 볼 수 있기 때문이다. 먼저 순서는 GDE에 대한 definition, Static Model에서의 GDE, Spatio-Temporal Model에서의 GDE순으로 이번 파트를 설명하고자 한다.</p>

<h3 id="1-definition-of-gde">(1) <strong>Definition of GDE</strong></h3>

<p>먼저 기존의 resiudal connection이 추가된 기존의 GNN이 업데이트되는 방식을 살펴보면 아래와 같이 나타낼 수 있다. 이때 함수 <strong>F</strong>는 GNN layer로 바라볼 수 있고, parameter는 layer별로 지정되는 것을 볼 수 있다. 또한 layer는 자연수의 범위 내에서 정의됨을 확인할 수 있다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891497-56ca0974-2521-4e6a-bfb4-5a75b5bf53b8.png" width="400" height="100" /></center>

<p>다음으로는 앞서 Motivation에서 살펴봤듯, residual connection을 좌변으로 넘겨서 이 term을 변화량의 관점에서 해석한 뒤, 미분방정식을 새롭게 만들어내었을 때 비로소 우리는 ‘<strong>Graph Neural Ordinary Differential Equation(GDE)</strong>‘의 초기값 문제(IVP)관점에서 아래와 같이 정의할 수 있게 된다. 중요한 점은, 위의 식과 달리 우리는 초기값을 가진 미분방정식을 Formulation 했다는 점이고, layer가 자연수 범위가 아닌 <strong>실수 범위</strong> 에서 정의된다는 점에 주목할 필요가 있다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891498-abf52002-9007-41a1-a8be-fd8eaffc2719.png" width="400" height="100" /></center>

<p>미분방정식을 Formulation하는 것도 중요하지만 또 하나의 중요한 점은 미분방정식의 해가 존재하는지 그리고 그 해가 유일한지 <code class="language-plaintext highlighter-rouge">Well-posedness</code>를 따져볼 필요가 있다. 우리는 이때, 적분구간을 [0,1]로 설정한 뒤, Hidden state에서의 <strong>Lipshitz Continuity</strong>, layer의 index로 해석될 수 있는 위의 식의 s에서의 <strong>Uniform Continuity</strong>를 조건으로 부여해줌으로써 해당 구간 내에서의 해(hidden representation)의 유일성을 정의할 수 있게 된다. 최종적으로 위의 hidden representation을 적분함으로써 우리는 GDE의 output을 아래와 같이 나타낼 수 있게된다. 이때, 적분구간을 [0,1]로 둔다고 하면, 0에서의 적분값은 정의한 미분방정식의 초기값과 만나 상쇄되게 된다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891500-a6e19194-c6c3-4cc3-868e-b30756718f47.png" width="400" height="100" /></center>

<h3 id="2-gde-on-static-models">(2) <strong>GDE on Static Models</strong></h3>

<p>우리는 GDE를 2가지 관점에서 해석할 수 있게 되는데 먼저 time에 variant하지 않은 static 모델에서 정의할 수 있다. Residual connection을 가진 GCN은 아래와 같이 나타낼 수 있게 되고 해당 식을 여태 위에서의 과정과 같이 미분 관점에서 해석하게 되면 아래 두 번째 식으로 나타낼 수 있게 된다. 이 때, L은 Laplacian Matrix를 나타내고 Hidden Representation을 나타내는 함수 <strong>F</strong> 는 모델링의 자유도를 가지는데 주로 Multilayer Convolution 등으로 표현할 수 있게 된다. 이 때, 우리는 GCN을 베이스로 하였기에 <code class="language-plaintext highlighter-rouge">Graph Convolutional Differential Equation, GCDE</code>로 GDE를 부를 수 있게된다.</p>

<p><img src="https://user-images.githubusercontent.com/68312164/174891503-81c3f455-4d2e-4c8c-be41-62324d0950fe.png" width="400" height="70" />
<img src="https://user-images.githubusercontent.com/68312164/174891506-d77b1b34-c226-44a1-bbc5-d00da4f33b0a.png" width="680" height="80" /></p>

<h3 id="3-gde-on-spatio-temporal-models">(3) <strong>GDE on Spatio-Temporal Models</strong></h3>

<p>다음으로는, 시간에 따라 variant한, autoregressive 속성을 가진 Spatio-Temporal 관점에서 GDE를 정의할 수 있다. 시간의 축을 포함시켜줌으로써, 우리는 depth domain을 time domain과 동치시킬 수 있다(RNN에서 layer를 쌓는다는 것은 그 만큼 더 많은 time input을 고려해준다는 의미와 상통된다고 생각하면 된다). 따라서 특정 시간에서 시간 변화량만큼 적분을 해줌으로써 우리는 Hidden representation을 업데이트할 수 있게 된다. 이 때 역시, 미분방정식의 관점에서 이를 해석할 수 있게되고, 시간 구간 내에서의 dynamic를 parameter <img src="https://latex.codecogs.com/svg.image?%5Cboldsymbol%7B%5Ctheta%7D" alt="" /> 를 가진 하나의 함수로서 나타낼 수 있게된다. GDE Framework에서 아래 등장하는, F, G, K는 <strong>GNN-operator</strong> 혹은 GNN layer로 생각할 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/68312164/174891508-881695d6-9a86-429d-b20e-55cbc8fbbb03.png" width="400" height="80" />
<img src="https://user-images.githubusercontent.com/68312164/174891512-3d2df150-6393-4e24-bcff-579cda78bc13.png" width="400" height="100" /></p>

<h2 id="4-experiment"><strong>4. Experiment</strong></h2>

<p>다음은 GDE의 효과성을 입증하기 위한 실험이다. 먼저 실험은 크게 3파트, <code class="language-plaintext highlighter-rouge">(1) Semi-supervised node classification</code>, <code class="language-plaintext highlighter-rouge">(2) Trajectory extrapolation task</code>, <code class="language-plaintext highlighter-rouge">(3) Traffic forecasting</code> 에서 진행되었다. 먼저 Overall하게 각 task에서 사용한 Dataset과 Baseline 그리고 Evaluation Metric을 정리하면 아래와 같이 나타낼 수 있다.</p>

<h3 id="experiment-setup"><strong>Experiment setup</strong></h3>

<ul>
  <li>Dataset
    <ul>
      <li>(1): Graph 분야에서 Benchmark dataset으로 꼽히는 Cora, Citeseer, Pubmed 기준으로 실험을 진행하였다. 특히 GDE의 Static 버전에서 실험을 진행하였다.</li>
      <li>(2): 시간에 따른 dynamical behavior를 효과적으로 살펴보기 위해 multi-particle system을 토대로 하였고 시간의 흐름에 따라 입자의 position, velocity의 trajectory가 어떻게 그려지는지 살펴보았다.</li>
      <li>(3): Undersampled 버전의 PeMS 데이터 셋을 활용하였고 이는 228개의 센서 스테이션이 5분의 주기로 교통량의 정보를 담고있는 데이터 셋이다.</li>
    </ul>
  </li>
  <li>baseline
    <ul>
      <li>(1): 기존의 GCN, GCDE가 가장 효과적이었을 때의 hyperparmeter 셋팅인 GCN* 을 사용하였고, 대표적인 Numerical Solver인 Runge-Kutta 2,4 그리고 Dormand-Prince를 비교하였다.</li>
      <li>(2): 다른 모델과의 비교에 초점을 두기보다는 position, velocity에서의 trajectory를 중점적으로 살펴보았다.</li>
      <li>(3): 시간에 따른 변화를 잘 모델링할 수 있는 기존의 GRU, 그리고 Graph Convolution을 접목시킨 GCGRU와 중점적으로 비교하였다.</li>
    </ul>
  </li>
  <li>Evaluation Metric
    <ul>
      <li>(1): Node classification task에서 주로 활용되는 test accuracy를 기반으로 하였다.</li>
      <li>(2): 업데이트 하는 과정에서 Mean Squared Error, MSE를 활용하였고, Figure로는 Trajectory를 제시하였다.</li>
      <li>(3): Root Mean Squared Error (RMSE)와 Mean Absolute Percentage Error (MAPE)를 활용하였다.</li>
    </ul>
  </li>
</ul>

<h3 id="result"><strong>Result</strong></h3>

<p><strong>(1) Semi-supervised node classification</strong></p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891515-bd91c64e-4b1d-4abb-988c-c527b0ac46e9.png" width="600" height="300" /></center>

<p>위의 Figure는 Node embedding 의 trajectory를 2차원으로 나타낸 그림인데 색은 node의 label이고 적분 구간이 종료점에 가까워질때까지 trajectories가 divergent하고 그말인 즉슨, label별로 update가 잘 일어나고 있음을 나타낸다.</p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891518-82fa904a-cc09-439d-b854-664591047e85.png" width="600" height="250" /></center>

<p>기존의 GCN, 그리고 가장 좋았던 hyperparmeter 셋팅을 바탕으로 한 GCN* 와의 비교 그리고 numerical solver의 variant로 비교를 한 Test accuracy이다. 성능이 압도하진 않지만 기존의 vanilla GCN 보다는 우월함을 드러내는 Table로 해석될 수 있다.</p>

<p><strong>(2) Trajectory extrapolation task</strong></p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891525-68dab104-4fb7-44cd-8353-08f6d1cc4c3c.png" width="600" height="300" /></center>

<p>이 task는 Extrapolation에서의 GDE의 퍼포먼스를 중점적으로 테스트한 결과인데, 변위 그리고 속도의 관점에서 입자의 trajectory를 plotting 한 결과이다. 총 10개의 particle system에서 측정하였기에 색은 총 10개의 variant한 입자를 나타내며, 각 입자별로 입자의 변위 그리고 속도 변화를 잘 표현해내고 있음을 확인할 수 있다.</p>

<p><strong>(3) Traffic forecasting</strong></p>
<center><img src="https://user-images.githubusercontent.com/68312164/174891521-b0832269-f9f4-495e-bb00-fb291637b2c7.png" width="700" height="100" /></center>

<p>Model에서의 퍼센티지는 Undersample 관점에서 해석하여, training 으로 활용한 데이터셋의 비율이다. 상대적으로 Harsh한 Undersampling 환경에서도 GCDE-GUR의 우월함을 확인할 수 있다. 앞선 static 실험에서와 달리 성능 향상의 폭이 유의미한 것을 확인할 수 있는데, 이로 유추해보아 확실히 time domain, continuous domain에서의 GDE의 효과성을 살펴볼 수 있다.</p>

<h2 id="5-conclusion"><strong>5. Conclusion</strong></h2>

<p>이로써 우리는 GNN과 Neural ODE가 처음으로 접목된, GDE를 살펴볼 수 있다. 오늘의 Paper는 퍼스트펭귄의 역할로서의 유의미함이 크고, 어떻게 Graph domain에 Neural ODE를 효과적으로 접목시킬 수 있는지에 대한 고민을 바탕으로 발전된 논문이다. 세줄 요약을 해보면 다음과 같다.</p>

<ul>
  <li>(1) GNN에 Neural ODE를 접목시킨 초창기 연구</li>
  <li>(2) Graph Neuarl Ordinary Differential Equation, GDE에 대한 정의</li>
  <li>(3) GDE에 대한 분류 - Static, Spatio-Temporal</li>
</ul>

<p>그리고, 필자는 이렇게 글을 마무리 짓고 싶다.</p>

<p><strong><code class="language-plaintext highlighter-rouge">GNN with Differential Equations? Way to go!</code></strong></p>

<h2 id="author-information"><strong>Author Information</strong></h2>

<ul>
  <li>Sukwon Yun (윤석원)
    <ul>
      <li>Master Student in ISySE, KAIST (<a href="http://dsail.kaist.ac.kr">DSAIL</a>)</li>
      <li>Interested in <strong>GNN, Differential Equations on NN, Long-Tail Problem on NN</strong></li>
      <li>Contact: swyun@kaist.ac.kr</li>
    </ul>
  </li>
</ul>

<h2 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h2>

<ul>
  <li>Paper: <a href="https://arxiv.org/abs/1911.07532">https://arxiv.org/abs/1911.07532</a></li>
  <li>Code: <a href="https://github.com/Zymrael/gde">https://github.com/Zymrael/gde</a></li>
  <li>Neural ODE: <a href="https://arxiv.org/abs/1806.07366">https://arxiv.org/abs/1806.07366</a>
    <ul>
      <li><strong>&lt; 도움이 되는 영상자료 모음 &gt;</strong></li>
      <li>직관적 이해: <a href="https://www.youtube.com/watch?v=AD3K8j12EIE">https://www.youtube.com/watch?v=AD3K8j12EIE</a></li>
      <li>논문의 key point: <a href="https://www.youtube.com/watch?v=jltgNGt8Lpg">https://www.youtube.com/watch?v=jltgNGt8Lpg</a></li>
      <li>최윤재 교수님 강의자료: <a href="https://www.youtube.com/watch?v=sIFnARdTVvE\&amp;t=3046s">https://www.youtube.com/watch?v=sIFnARdTVvE\&amp;t=3046s</a></li>
      <li>Adjoint Sensitivity Method: <a href="https://www.youtube.com/watch?v=k6s2G5MZv-I\&amp;t=512s">https://www.youtube.com/watch?v=k6s2G5MZv-I\&amp;t=512s</a></li>
    </ul>
  </li>
  <li>GCN: <a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a>
    <ul>
      <li>PDF 자료: <a href="https://github.com/SukwonYun/GNN-Papers">https://github.com/SukwonYun/GNN-Papers</a></li>
      <li>윤훈상 연구원님 자료: <a href="https://www.youtube.com/watch?v=F-JPKccMP7k\&amp;t=635s">https://www.youtube.com/watch?v=F-JPKccMP7k\&amp;t=635s</a></li>
    </ul>
  </li>
  <li>Github Review (본문 사진이 잘 안보일 경우): <a href="https://github.com/SukwonYun/awesome-reviews-kaist/blob/2022-Spring/paper-review/2022-spring/AAAI-2020-GDE.md">https://github.com/SukwonYun/awesome-reviews-kaist/blob/2022-Spring/paper-review/2022-spring/AAAI-2020-GDE.md</a></li>
</ul>]]></content><author><name></name></author><category term="그래프" /><category term="paper-review" /><summary type="html"><![CDATA[Michael Poli, Stefano Massaroli / Graph Neural Ordinary Differential Equations / AAAI(DLGMA)-2020]]></summary></entry><entry><title type="html">[지식그래프] (TransE) Translating Embeddings for Modeling Multi-relational Data</title><link href="https://sukwonyun.github.io/blog/2021/TransE/" rel="alternate" type="text/html" title="[지식그래프] (TransE) Translating Embeddings for Modeling Multi-relational Data" /><published>2021-02-08T23:27:23+00:00</published><updated>2021-02-08T23:27:23+00:00</updated><id>https://sukwonyun.github.io/blog/2021/TransE</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2021/TransE/"><![CDATA[<p>Bordes, Antoine, et al. “Translating embeddings for modeling multi-relational data.” Neural Information Processing Systems (NIPS). 2013.</p>

<h3 id="in-short-embedding-entities-and-relationships-in-same-space"><em>In short, “Embedding Entities and Relationships in Same space”</em></h3>

<h3 id="about">About</h3>

<p>이 논문은 지식 그래프에서 가장 기반이 되는 Translation-based model 이라고 할 수 있고, 저 차원의 벡터 공간에서 가볍고 성능이 좋은 모델을 제시하는데 의의가 있다.</p>

<h3 id="abstract">Abstract</h3>

<p>지금 우리가 해결할 문제는 구성요소와 관계들을 저차원의 벡터 공간으로 임베딩 시키는 것이고, 무엇보다 지식 그래프의 기반이 되고 학습하기 쉬운 장점을 가지는 것을 목표로 한다. 이에 TransE 라는 모델을 제시하는데 이 모델은 <strong>relationship</strong>(관계)를  저차원의 임베딩된 구성요소간 <strong>translations</strong>(전환)  으로 해석한다는 것이 핵심이다.</p>

<h3 id="1-introduction">1. Introduction</h3>

<h4 id="modeling-multi-realtional-data">Modeling multi-realtional data</h4>
<ul>
  <li>Multi-relational data 란 무엇일까?</li>
</ul>

<p>단어에서 유추할 수 있듯이 많은 관계를 표현하는게 우선시되어 보인다. 이는, <strong>directed graph</strong>(방향을 가진 그래프) 에서 nodes와 edges를 entities(head, tail), label로 표현한 것으로 다음과 같이 나타낼 수 있다.  $(head, label, tail)$ 의 의미를 가진 $(h,l,t)$ 로 간략화 할 수 있고 주로 사회 네트워크 망이나 친구 관계, 소셜 네트워크 등에서 주로 사용된다. 이때 우리의 목표는 KB, 지식 그래프에서 발생하는 다수의 관계를 효과적으로 모델링하여 새로운 정보가 들어오면 별도의 지식없이 자동적으로 정보를 업데이트 해주는 것이다.</p>

<p>이때, realtional data, 즉 관계를 가지는 데이터에서 중요한점은 locality, 국소적인 관계에 있어 구성요소와 관계가 서로 다른 타입의 데이터를 동시에 가질 수 있다는 점이다. 이에 multi-relational, 다양한 관계를 가진 데이터를 표현할 때는 좀 더 일반적인 접근이 필요하다. 그리고 추천시스템에서 주로 다루는 Matrix factorization  의 성질을 이용한 single, multi-realtional 관계 표현에 이어 2013년에 발표된 ‘<em>A semantic matching energy function for learning with multi-realtional data</em>‘에 의하면,  복잡하고 여러 타입의 데이터 타입이 포함된 multi-relational 도메인에서 linear하고 simple한 모델이 정확성과 확장성 사이의 절충을 더욱 잘 표현할 수 있음을 시사한다.</p>

<p><img src="https://user-images.githubusercontent.com/68312164/107507619-2eb08280-6be3-11eb-8b54-e25b7d8f54e3.png" alt="image" /></p>

<h4 id="relationships-as-translations-in-the-embedding-space">Relationships as translations in the embedding space</h4>
<p>이 논문에서 제시하는 TransE라는 energy-based 모델은  구성요소들의 저차원 임베딩을 학습하는데 의의를 가지고 관계들을 임베딩 공간에서의 전환으로 표현될 수 있다. 이때 핵심은 <strong>$(h,l,t)$가 성립한다면, $h+l \approx t$</strong> 가 성립한다는 점이다. 즉, <strong>임베딩 된 tail entity $t$는 임베딩 된 head entity $h$ 와 realtionship 과 관련된 벡터 $l$ 과의 합과 가까이 위치한다</strong>는 의미로 볼 수 있다.</p>

<p>이 식에 대한 모티베이션은 간단히 두 가지 인데 아래와 같다.</p>
<ol>
  <li>지식그래프에서 흔히 볼 수 있는 계층적인 관계(부모-자식, 자녀 관계)를 잘 표현할 수 있는게 결국, translation 이다.</li>
  <li>노드 타입이 다른 1-to-1 관계를 좀 더 용이하게  표현할 수 있는게 역시, translation 이다.</li>
</ol>

<h3 id="2-translation-based-model">2. Translation-based model</h3>

<p>훈련 데이터 셋에서 모델의 핵심은 구성 요소들과 관계를 잘 나타내는 저차원의 벡터 임베딩을 학습하는 것이다. 머신러닝에서 항상 그래왔듯, 학습을 하기 위해서는 손실 함수가 정의 되어야고 정의된 손실함수가 어느 방향(최소화 방향) 으로 학습을 진행하면 될지를 알려주는 이정표가 될 것이다. 이 때 손실함수는 margin-based ranking criterion 으로 정의하는데 목적식을 정의하기 이전에 다음과 같은 맥락을 이해해야 한다.</p>

<ul>
  <li>\(h,t\in E\)(set of entities), \(l \in L\)(set of relationships)</li>
  <li>임베딩 벡터의 차원: \(\mathbb{R}^{k}\)(k는 실험자 지정 하이퍼파라미터)</li>
  <li>energy of triplet: \(d(h+l, t)\), \(d\)는 dissimilarity measure로 주로 \(L_{1}, L_{2} - norm\)</li>
  <li>\(\gamma\)는 margin hyperparameter</li>
</ul>

\[\mathcal{L}= \sum_{(h,l,t)\in S} \sum_{(h',l,t')\in S'_{(h,l,t)}}\left [ \gamma +{d} \mathbf{(h+l,t)} -d\mathbf{(h'+l,t')})\right ]_{+}\]

<p>이때,</p>

\[S'_{(h,l,t)} = \left \{ (h',l,t)|h' \in E \right \} \cup \left \{ (h,l,t')|t' \in E \right \}\]

<p>위의 Set은 Corrupted triplet이라고 할 수 있는데, 이때 Corrupted 는 ‘노이즈가 있는’ 상태라고 이해하면 될 것 같다. head 와 tail 중 하나의 요소만 랜덤한 entity 값으로 변경해주고 각각의 경우를 합하여 하나의 집합으로 표현한 Set으로 이해하면 된다. 또한, 위의 Loss function에서 우리는 training triplet $(h,l,t)$ 의 energy(dissimilarity) 가 낮은 상황, $(h’,l,t’)$ 의 energy(dissimilarity) 가 높은 상황을 원하므로 위의 손실 함수가 합리적으로 정의된 면모를 확인할 수 있다. 최적화는 mini-batch의 SGD를 통해 일어나게 되고, $L_{2}$-norm 을 1로 제한한다.  상세한 최적화 알고리즘은 아래와 같다.</p>

<center><img src="https://user-images.githubusercontent.com/68312164/107486444-652cd400-6bc8-11eb-98f5-3a72be295145.png" width="750" height="500" /></center>

<p>간략히 이해해보면,<br />
(1) relationship 을 표현하는 집합 내 원소인 l 에 대해서 유니폼 분포를 따르게 해주고, 정규화 해준다. <br />
(2) Entity Set 내의 구성요소 역시 유니폼 분포 내에 특정 값을 가지게 해준다.<br />
(3) 구성요소를 정규화 해주고, minibatch size인 b로 training set $(h,l,t)$ 가 b개 있는 $S_{batch}$ 를 구성하고, $T_{batch}$를 초기화 시켜준다.<br />
(4) $S_{batch}$ 안에 있는 모든 triplet에 대해 각각 Corrupted 된 Set을 만들어주고 $T_{batch}$ 에 원소로 넣어준다.<br />
(5) 구성된 $T_{batch}$를 통해 편미분한 목적식을 바탕으로 임베딩을 업데이트 시켜준다.<br />
(6) (2) - (5) 를 반복한다.</p>

<p>이러한 TransE 는 기존의 제시된 SE <em>(Learning structured embeddings of knowledge bases, 2013)</em> 모델 보다 설명력은 약할 수 있지만, 관계를 더욱 잘 반영한다는 점과 임베딩된 모델에 대한 최적화가 어렵다는 점에서 기존의 SE보다 우월함을 가지게 된다. 이러한 TransE는 간단하면서도 효과적인 모델로 이해할 수 있는데, 2-way interactions를 표현하는데 있어 강점을 가진다. 반면 ,$h,l,t$ 간의 상호종속적인 관계, 3-way dependencies를 표현하는데는 약점을 가진다. 또한 1-to-1 이상의 , 1-to-N, N-to-1 관계를 포함하는데 TransE는 부적합할 수 있다.</p>

<h3 id="3-conclusion">3. Conclusion</h3>
<p>저자는 지식그래프 임베딩의 새로운 학습 관점을 제시하였다. 계층적인 관계를 표현하기 위해 최소한의 변수들을 바탕으로 기존의 지식 그래프 모델들보다 효과적인 퍼포먼스를 보여주었다. 또한, 가벼운 모델을 바탕으로 확장성또한 TransE만의 강점이라고 표현할 수 있다.</p>

<h3 id="세-줄-요약">세 줄 요약</h3>
<ol>
  <li>Relationships = 저차원의 임베딩 공간에서의 Translations</li>
  <li>Corrupted Triplet 도입하여 손실 함수 정의</li>
  <li>가볍고, 성능 좋음. 1-to-1에 효과적이라는 한계</li>
</ol>

<h3 id="references">References</h3>
<ol>
  <li>Bordes, Antoine, et al. “Translating embeddings for modeling multi-relational data.” Neural Information Processing Systems (NIPS). 2013.</li>
</ol>]]></content><author><name></name></author><category term="지식그래프" /><summary type="html"><![CDATA[Bordes, Antoine, et al. “Translating embeddings for modeling multi-relational data.” Neural Information Processing Systems (NIPS). 2013.]]></summary></entry><entry><title type="html">[추천시스템] Wide &amp;amp; Deep Learning for Recommender Systems</title><link href="https://sukwonyun.github.io/blog/2021/WideDeep/" rel="alternate" type="text/html" title="[추천시스템] Wide &amp;amp; Deep Learning for Recommender Systems" /><published>2021-01-20T16:37:28+00:00</published><updated>2021-01-20T16:37:28+00:00</updated><id>https://sukwonyun.github.io/blog/2021/WideDeep</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2021/WideDeep/"><![CDATA[<p>Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st workshop on deep learning for recommender systems. 2016.</p>

<h3 id="in-short-memorization-wide--generalization-deep"><em>In short, “Memorization (Wide) + Generalization (Deep)”</em></h3>

<h3 id="about">About</h3>

<p>이 논문은 추천시스템의 Memorization, Generalization 의 장점을 결합한 새로운 학습 방법을 제시해주는 논문이다.</p>

<h3 id="abstract">Abstract</h3>

<p>Generalization 모델은 적은 수의 인풋을 가진 대규모의 회귀나 분류 문제에 적합하고 Memorization 모델은 외적을 바탕으로 한 효과적이고 설명력이 높은 특성을 가진다.
이 논문에서는 Wide &amp; Deep Learning 이라는 Wide Linear 모델과 DNN 의 장점만을 결합한 모델을 새롭게 제시한다.</p>

<h3 id="1-introduction">1. Introduction</h3>

<p>추천 시스템은 인풋으로 쿼리(데이터베이스에 정보를 요청하는)와 맥락적인 정보를 가지고 아웃풋으로는 순위가 매겨진 아이템을 가지는 랭킹 시스템이라고 볼 수 있다. 이러한 목적 하에 주로 발생하는 문제는 Memorization 과 Generalization 의 특성을 모두 가져가는 것이다. 간단히 설명하자면, <strong>조류가 날아다니는 사진을 보여준 상황</strong>에서 아래와 같이 설명할 수 있다.</p>
<ul>
  <li><strong>Wide (Memorization)</strong>: <strong>비둘기는 날 수 있다</strong>, <strong>참새는 날 수 있다</strong></li>
  <li>
    <p><strong>Deep (Generalization)</strong>: <strong>날개를 가진 동물은 날 수 있다</strong></p>
  </li>
  <li><strong>Wide &amp; Deep</strong>: <strong>‘날개를 가진 동물은 날 수 있지만, 펭귄은 날 수 없다’</strong></li>
</ul>

<p><img src="https://user-images.githubusercontent.com/68312164/105043795-4d6e9e00-5aa9-11eb-805b-f0a9248b624e.png" width="200" height="250" /> <img src="https://user-images.githubusercontent.com/68312164/105043929-798a1f00-5aa9-11eb-9b49-1962dc8b6210.png" width="200" height="250" /> <img src="https://user-images.githubusercontent.com/68312164/105044095-ab9b8100-5aa9-11eb-9d07-523b7ea10fcc.png" width="200" height="250" /></p>

<h4 id="wide-model">Wide Model</h4>
<p><img src="https://user-images.githubusercontent.com/68312164/105060951-4a30dd80-5abc-11eb-995c-214a73c3ddbd.png" width="600" height="300" /></p>

<p>먼저 Wide 모델에서는 위와 같이 User feature, Impression feature 그리고 Crossed feature를 input으로 가지게 된다. 유저가 실제로 설치한 여행 앱, ’Priceline’ 을 1이라고 하고, 유저가 관심을 보인 ‘Kayak’ 앱을 1이라고 했을 때 둘을 곱한 1이 Crossed Feature가 된다. 이러한 방식은 1인 경우만 학습을 하기에 유저의 niche 한 특성이 잘 반영되는 한편, User feature, Impression feature 중 하나가 0 이면 Crossed feature 역시 학습이 불가능하다는 한계를 가진다.</p>

<h4 id="deep-model">Deep Model</h4>
<p><img src="https://user-images.githubusercontent.com/68312164/105061021-5ae15380-5abc-11eb-88e9-72bbb555adab.png" width="345" height="300" /> <img src="https://user-images.githubusercontent.com/68312164/105061111-79dfe580-5abc-11eb-9673-ee80dec0d90f.png" width="345" height="300" /></p>

<p>다음으로 Deep 모델에서는 구체화된 ‘Priceline’, ‘Kayak’ 과 같은 앱이 아닌 ‘Travel’ 이라는 큰 범주 하에서 feature를 구성하게 된다. 이 경우, 위에서 0 이었던 값들이 Dense한 임베딩 공간(오른쪽)으로 옮겨져서 값을 부여받아서 더욱 일반화 된(큰 범주에서) 값을 잘 표현할 수 있게된다. 하지만, 앞서 표현했던 뚜렷한 niche 한 관계는 잘 표현하지 못한다는 단점을 가지게 된다. 이러한 장단점을 잘 표현한 그림은 아래와 같다.</p>

<p><img src="https://user-images.githubusercontent.com/68312164/105061144-849a7a80-5abc-11eb-95ca-d5e121b80c8a.png" width="345" height="300" />   <img src="https://user-images.githubusercontent.com/68312164/105061198-98de7780-5abc-11eb-8d7a-5e6d6e56c9d5.png" width="345" height="300" /></p>

<p>먼저 왼쪽은 Deep 모델이 유리한 경우인데, 상대적으로 유사한 가중치를 가질 때 임베딩 공간으로 옮겨지게 되면서 파라미터 수가 줄어드는 것을 확인할 수 있다. 이러한 특성은 추천시스템의 MF에서 SVD와 같은 latent space가 가지는 의미와 일맥상통하고 PCA 특성 또한 함유하고 있다. 반면 오른쪽에서와 같이 Spase하고 niche 할때는 Deep 모델이 상대적으로 불리할 수 있고 같은 임베딩 공간 내에서 서로 다른 클러스터를 밀어내기가 힘들어 상대적으로 덜 유의한 앱을 추천할 가능성을 가지게 된다.</p>

<p>즉, 정리하면</p>
<ul>
  <li>Dense, similar -&gt; Deep 유리</li>
  <li>Sparse, niche -&gt; Wide 유리</li>
</ul>

<h3 id="2-recommender-system-overview">2. Recommender System Overview</h3>
<p><img src="https://user-images.githubusercontent.com/68312164/105073305-3be9be00-5aca-11eb-81af-4d86a8b1437e.png" width="650" height="330" /></p>

<p>추천시스템의 개략적인 구조를 살펴보면 위와 같은데, 쿼리를 인풋으로 받아서 유저에게 Item 간 랭크를 매겨 추천해주고 이에 대한 액션과 앞선 쿼리를 로그에 담아 학습하고 다시 랭킹을 메기는 시스템 구조이다.
이 논문에서는 랭킹을 메기는 과정에서 Wide&amp;Deep 학습 방법을 기반으로 하는 것에 중점을 둔다.</p>

<h3 id="3-wide--deep-learning">3. Wide &amp; Deep Learning</h3>

<h4 id="the-wide-component">The Wide Component</h4>
<p><img src="https://user-images.githubusercontent.com/68312164/105074368-98011200-5acb-11eb-9980-307b80445dd8.png" width="650" height="330" /></p>

<p>Wide 모델에서는 아래와 같은 선형의 관계를 나타내게 되는데, 이때 feature set \(\textbf{x}\) 는 raw input feature와 transformed된 feature로 구성된다.</p>

\[y = \textbf{w}^T \textbf{x} + b\]

\[where, \textbf{x} = [x_1,x_2,...,x_d],  \textbf{w} = [w_1,w_2,...,w_d],  b = bias\]

<p>이때, raw input과 함께 구성되는 feature는 <em>cross-product transformation</em> 을 거치게 되는데 아래와 같이 정의된다.</p>

\[\phi_{k}(\textbf{x}) = \prod_{i=1}^{d}x_{i}^{c_{ki}}, c_{ki} \in \left \{ 0,1 \right\}\]

<p>간단한 예시로는, 다음과 같이 binary한 상황을 가정하면 아래와 같이 표현할 수 있다.</p>

\[gender = \left [ male, female \right ] = \left [ 1,0 \right ]\]

\[married = \left [ yes, no \right ] = \left [ 1,0 \right ]\]

\[language = \left [ english, koeran \right ] = \left [ 1,0 \right ]\]

<p>이때, user A가 male이고 married 한 상태이고 korean 이면 아래와 같은 벡터를 가지게 된다.</p>

\[\textbf{x} = \left [ gender, married, language \right ] = \left [ 1,1,0 \right ]\]

<p>이때, transformation \(\phi_{k} \left ( k = 1,2,3 \right)\) 에서 \(k=1\)인 상태가, married와 language의 조합을 나타내는 transformation이라고 한다면,
\(\phi_{1} \left (\textbf{x} \right )\) 는 아래와 같이 나타낼 수 있다.</p>

\[\phi_{1} \left (\textbf{x} \right ) = x_1^{c_{11}}x_2^{c_{21}}x_3^{c_{31}} = 1^0 1^1 0^1 = 1\]

<h4 id="the-deep-component">The Deep Component</h4>
<p><img src="https://user-images.githubusercontent.com/68312164/105074332-8f104080-5acb-11eb-9a91-07e5b6f9f0c3.png" width="650" height="330" /></p>

<p>Deep 모델에서는 순전파의 신경망을 생각하면 되는데, 이때 \(\textbf{a}\)는 Continuous feature와 Categorical feature를 concat하여 input으로 사용한다. Categorical feature는 임베딩을 거쳐 dense한 벡터로 구성되어 합쳐진다.</p>

\[\textbf{a}^{\left ( l+1 \right )} = f\left (\textbf{W}^{\left ( l \right )}\textbf{a}^{\left ( l \right )}+\textbf{b}^{\left ( l \right )}   \right)\]

<p>이떼, \(l\)은 레이어 번호, \(f\)는 ReLu와 같은 활성화 함수, \(W\)는 가중치 행렬, \(b\)는 편향을 의미한다.</p>

<h4 id="joint-training-of-wide--deep-model">Joint Training of Wide &amp; Deep Model</h4>
<p><img src="https://user-images.githubusercontent.com/68312164/105078865-ed402200-5ad1-11eb-820d-b3919a06bb5a.png" width="650" height="330" /></p>

<p>최종 모델은 앞선 wide, deep 모델의 특성을 합쳐서 하나의 목적식, prediction으로 표현한다고 볼 수 있다. logistic regression 문제에서 모델의 예측식은 아래와 같다.
이때, 아웃풋에서 출발하는 역전파를 wide, deep 방향 모두가 전파 받고 모델이 동시에 mini-batch 학습을 하게 된다. 동시에 두 파트가 학습되는 점이 각 모델들이 학습된 이후 최종적으로 합쳐지는 앙상블 모델과 차별화되는 점이다. 실제 Wide &amp; Deep 실험에서는, wide 파트에서는 FTRL + L1 알고리즘을 사용하였고, deep 파트에서는 AdaGrad 를 optimizer로 사용하였다. 아래 식에서 \(P(Y=1 | \textbf{x})\)는 feature vector가 인풋으로 주어졌을 때 실제 특정 앱을 수용할 확률, app acquisition 확률로 이해하면 된다.</p>

\[P(Y=1 | \textbf{x}) = \sigma\left ( \textbf{w}_{wide}^T\left [ \textbf{x}, \phi\left ( \textbf{x} \right ) \right ] + \textbf{w}_{deep}^T a^{\left ( l_{f} \right )} + b \right)\]

<h3 id="4-system-implementation">4. System Implementation</h3>

<p>앱 추천 시스템의 파이프라인은 아래와 같이 Data Generation, Model Training, Model Serving 3 단계로 구성된다.<br />
 <img src="https://user-images.githubusercontent.com/68312164/105080633-70627780-5ad4-11eb-893b-3a35e896fb30.png" width="650" height="330" /></p>

<p>이때, Model training 단계에서 매번 재학습을 방지하기 위해 <strong>warm-starting</strong>로 이전 모델의 임베딩과 linear 모델 가중치를 새로운 모델에 적용한다는 점도 주목할 만한 점이다.</p>

<h3 id="5-experiment-results">5. Experiment Results</h3>
<p><img src="https://user-images.githubusercontent.com/68312164/105080975-ef57b000-5ad4-11eb-94a5-930f01039f6c.png" width="350" height="170" /><img src="https://user-images.githubusercontent.com/68312164/105080997-f67ebe00-5ad4-11eb-968d-a53b261cfa44.png" width="350" height="170" /></p>

<p>Wide 모델은 대조군으로 설정하고 Wide &amp; Deep 모델을 실험군으로 설정했을 때, 4% 정도의 수용률 증가를 얻어냈고, online traffic일때 더욱 좋은 퍼포먼스를 보여주었다. 또한 Batch를 더욱 분할하여 진행했을 때, 속도 또한 효과적임을 확인할 수 있었다.</p>

<h3 id="6-conclusion">6. Conclusion</h3>
<p>저자는 Factorization Machines(Rendle, Steffen. 2010) 에서 많은 영향을 받았다고 한다. 그리고 FM에서 주 컨셉이었던 임베딩 공간에서의 벡터 내적 대신에 신경망과 결합된 임베딩으로 한층 더 비선형적인 관계까지 확장해나갔다. 이로써 다시 한 번 정리하면, Memorization을 Wide linear model에서 cross product를 통해 이루어 냈고, Generalization을 DNN을 통해 효과적으로 이루어 내어 두 컨셉을 결합해 하나의 통합적인 모델을 제시하였다.</p>

<h3 id="세-줄-요약">세 줄 요약</h3>
<ol>
  <li>Memorization = Wide Linear Model + Cross-product transformation</li>
  <li>Generalization = Deep Neural Network</li>
  <li>Wide &amp; Deep = Memorization + Generalization</li>
</ol>

<h3 id="references">References</h3>
<ol>
  <li>Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st workshop on deep learning for recommender systems. 2016.</li>
  <li>Wide &amp; Deep Learning: Memorization + Generalization with TensorFlow (TensorFlow Dev Summit 2017), https://www.youtube.com/watch?v=NV1tkZ9Lq48</li>
  <li>https://leehyejin91.github.io/post-wide_n_deep/</li>
</ol>]]></content><author><name></name></author><category term="추천시스템" /><summary type="html"><![CDATA[Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st workshop on deep learning for recommender systems. 2016.]]></summary></entry><entry><title type="html">[추천시스템] Probabilistic Matrix Factorization</title><link href="https://sukwonyun.github.io/blog/2021/pmf/" rel="alternate" type="text/html" title="[추천시스템] Probabilistic Matrix Factorization" /><published>2021-01-07T11:52:07+00:00</published><updated>2021-01-07T11:52:07+00:00</updated><id>https://sukwonyun.github.io/blog/2021/pmf</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2021/pmf/"><![CDATA[<p>Mnih, Andriy, and Russ R. Salakhutdinov. “Probabilistic matrix factorization.” Advances in neural information processing systems 20 (2007): 1257-1264.</p>

<h3 id="abstract">Abstract</h3>
<ul>
  <li>CF 단점: large datasets with few rating
    <ol>
      <li>PMF -&gt; large, sparse에 강건함</li>
      <li>적응형 모델, 용량 제어</li>
      <li>user에 대한 제약 조건 있을때 PMF</li>
    </ol>
  </li>
</ul>

<h3 id="1-introduction">1. Introduction</h3>
<ul>
  <li>Low-dimensional factor models -&gt; small number of unobserved factors</li>
  <li>Linear factor model: 사용자의 선호도가 user-specific coefficient 를 사용한 item factor vector의 선형결합으로 이루어짐</li>
  <li>preference matrix R: N x M</li>
  <li>user coefficient matrix U’: N x D</li>
  <li>factor matrix V: D x M</li>
  <li>
    <p>R = U’ x V
-&gt; finding best rank-D approximation</p>
  </li>
  <li>
    <p>최근 제시된 모델에 따르면 hidden factor 변수가 user rating 을 표현하는데 connection 가짐. 하지만 정확한 추론이 intractable 하다는 단점. hidden factor 에 대한 사후 분포 연산 등이 느리거나 부정확함</p>
  </li>
  <li>
    <p>SVD -&gt; R=U’V  로 추론해서 실제 R 과 거리 최소화되는 R 찾는 것. 오직 관찰된 값들에 대해서 계산되고 조그만 변화에 의해서도 non-convex 문제에 해당돼서 어려워진다</p>
  </li>
  <li>
    <p>랭크에 대한 제약을 두는 방법 대신에 U, V의 크기에 패널티를 주는 방식도 데이터가 커지면 Sparse Semi-definite program이 돼서 어려워진다.</p>
  </li>
  <li>위의 방법들이 효과적이지 않았던 이유는, Large scale에 적합하지 않았고, few ratings에 대한 정확한 추론이 어려웠다. 이에 실제 MovieLens, EachMovie 등의 데이터에선 일정 수 이하의 평가를 한 유저는 제거했다. Netflix data는 imbalance하고 이러한 면이 현실의 특성을 더욱 잘 반영한다.</li>
  <li>이 논문의 목적은 다음과 같다.
    <ol>
      <li>scale에 linear한 드물고 imbalance에 강건히 대응하기 위한 PMF 제안.</li>
      <li>PMF에서 user preference matrix 는 lower-rank user, movie matrices 로 구성</li>
      <li>모델 복잡도를 조절할 수 있는 adaptive prior 포함한 PMF 모델 제시</li>
      <li>User 입장에서의 Constraint 가진 PMF 제안</li>
      <li>기존 SVD 보다 효과적임을 입증, 특히 constrained PMF가 적은 rating에 효과적</li>
    </ol>
  </li>
</ul>

<h3 id="2-probabilistic-matrix-factorizationpmf">2. Probabilistic Matrix Factorization(PMF)</h3>
<ul>
  <li>M movies</li>
  <li>N users</li>
  <li>1 to K ratings</li>
  <li>U = D x N (latent user feature matrix)</li>
  <li>V = D x M (latent movie feature matrix)</li>
  <li>Uj = user specific latent feature vector</li>
  <li>
    <p>Vj = movie-specific latent feature vector</p>
  </li>
  <li>모델 성능이 RMSE로 평가되기 때문에, probabilistic linear model with Gaussian observation noise 을 test set에 채택한다</li>
  <li>이때 Iij는 indicator function 으로 i가 j를평가했으면 1, 아니면 0으로 표기된다.</li>
  <li>그리고 zero-mean spherical Gaussian prior를 user and movie feature vector에 적용한다.</li>
  <li>
    <p>이후, log of posterior distribution 을 최대화하는 건 이차항의 정규화 텀을 넣은 목적식의 SSE를 최소화하는 것과 같다. (단, variance 등의 하이퍼파라미터 고정)</p>
  </li>
  <li>목적식을 최소화하는, local minimum은 U, V에 대한 경사 하강법을 적용시키면 된다</li>
</ul>

<p>이 모델은 SVD의 probabilistic extension이다. 모든 평점들이 관측되는 조건이라면, SVD와 동일할 것이다. 단, prior variance 인 sigma_u, sigma_v가 무한으로 간다면 정의한 람다_u, 람다_v가 0으로 갈 것이기에.</p>

<ul>
  <li>이 논문에서는 위의 linear-Gaussian model 대신에 range 범위를 조절하기 위해 U,V의 내적 값이 dot product 안에 해당될 수 있도록 sigmoid를 거치게 해준다. 즉, 정규분포의 평균 값이 0~1 사이의 범위를 가지게 해준다. 동시에 rating 값도 t(x) = x-1 / K-1 로 조절해준다. 목적식을 최소화하는 알고리즘은, steepest descent algorithm을 사용하는데, 관측치에 선형적으로 비례하는 시간이 소요된다.</li>
</ul>

<h3 id="3-automatic-complexity-control-for-pmf-models">3. Automatic Complexity Control for PMF Models</h3>
<ul>
  <li>
    <p>PMF 모델이 더욱 일반화 되기 위해서 Capacity Control이 중요해지는데 통상적으론 feature vector의 dimensionality를 줄이는 방법, 정규화 텀을 도입하는 방법이 있는데 각가 데이터 셋이 언밸런스한 경우 효과적이지 않고, 찾기 위해 계산비용이 많이 든다는 점에서 단점을 가진다.</p>
  </li>
  <li>
    <p>이 논문에서는 PMF 모델에서 정규화 파라미터를 학습하는데 시간을 많이 들이지않고 자동적으로 찾아내는 방법을 제안한다.</p>
  </li>
  <li>
    <p>파라미터와 하이퍼파라미터의 점 추정을 log-posterior 를 최대화하는 방법을 기반으로 한다. MAP estimation과 spherical  prior 사용을 통해 하이퍼파라미터 자동 결정한다. diagonal, full covariance matrix 등을 사용한다.</p>
  </li>
  <li>
    <p>Prior가 Gaussian 이면, 최적화된 하이퍼파라미터가 closed form이고 하이퍼파라미터 최적화와 고정된 하이퍼파라미터로 steepest ascent 를 사용해 feature vector를 업데이트 하는 방법을 번갈아서 진행한다.</p>
  </li>
  <li>
    <p>Prior가 Mixture of Gaussian 이면, EM 방법으로 하이퍼파라미터가 업데이트 되고 close form을 하이퍼파라미터에 대한 conjugate prior을 다루기 위해 연장하기가 수월하다. conjugate = prior, posterior 같을 때.</p>
  </li>
</ul>

<h3 id="4-constrained-pmf">4. Constrained PMF</h3>
<ul>
  <li>infrequent user에 대해 user-specific feature vector에 대한 제약을 새롭게 정의해서 제안한다.</li>
  <li>W = D x M (similarity constraint matrix)
W의 i번째 열은 한 유저가 평가한 특정 영화가 그 유저의 feature vector의 prior mean에 대해 얼마만큼의 영향력을 가졌는지 나타낸다. (prior mean 이라고 생각, 즉 0으로 설정했던 mean과 달리 0 이 아닐때의 영향력 고려)</li>
</ul>

<p>결과적으로, 같은 영화를 본 유저들은 그들의 feature vector에 대한 비슷한 prior distribution을 가진다.</p>

<ul>
  <li>이때 Yi 는 mean of prior distribution에 더해진 offset 역할을 한다.U’V에 넣어주고 sigmoid를 거쳐준다.</li>
</ul>

<p>W를 정규화해주기 위해 zero-mean spherical Gaussian prior로 mu를 넣어준다.</p>

<ul>
  <li>최종 quadratic regularization term을 만들어주고 SSE를 최소화하는 목적식을 설정해준다. 경사하강법으로 Y, V, W를 구해주고 constrained PMF의 경우, 빠르고 간단한 학습이 가능하다.</li>
</ul>

<h3 id="5-experimental-results">5. Experimental Results</h3>
<h4 id="51-description-of-netflix-data">5.1 Description of Netflix Data</h4>
<ul>
  <li>
    <p>넷플릭스 데이터에 대한 설명, validation data, test det 등. 오버피팅 방지를 위해 RMSE 척도 사용</p>
  </li>
  <li>
    <p>추가적인 인사이트를 위해 이 논문에서는 더 까다로운 설정을 함. 50%가 넘는 사용자들이 10개 이하의 영화에 평점을 매김</p>
  </li>
</ul>

<h4 id="52-details-of-training">5.2 Details of Training</h4>
<ul>
  <li>100,000 mini-batch로 설정 한 mini-batch 이후에 feature vector update</li>
  <li>lr = 0.005, momentum = 0.9</li>
</ul>

<h4 id="53-results-for-pmf-with-adaptive-priors">5.3 Results for PMF with Adaptive Priors</h4>
<ul>
  <li>
    <p>PMF with adaptive prior 의 성능 평가를 위해 10차원의 feature를 씀.</p>
  </li>
  <li>PMF1: 람다_u = 0.01, 람다_v = 0.001</li>
  <li>PMF2: 람다_u = 0.001 람다_v = 0.0001</li>
  <li>PMFA1: spherical covariance (adaptive)</li>
  <li>PMFA2: diagonal covariance (adaptive)</li>
  <li>10, 100번의 데이터 처리할때마다 업데이트</li>
  <li>
    <p>SVD, PMF2 초반에 괜찮다가 SVD 오버핏하는 경향, PMF1 underfit 하는 경향, 따라서 adaptive 한 경우가 실제상황에서 퍼포먼스가 좋다</p>
  </li>
  <li>use of adaptive prior 의 효과성, 때론 diagonal covariance가 greedy version에 효과적.</li>
</ul>

<h4 id="54-results-for-constrained-pmf">5.4 Results for Constrained PMF</h4>
<ul>
  <li>D=30, 람다=0.002, SVD-&gt; 심하게 overfit</li>
  <li>
    <p>constrained PMF가 unconstrained PMF보다 빠르게 수렴하고 적은 수의 관측에서 PMF 보다 효과적.  관측 수 많아질수록 두 PMF의 성능은 비슷해짐</p>
  </li>
  <li>
    <p>또 하나의 흥미로운 측면은, 어떤 영화를 봤는지만 알고 실제 rating은 모르는 경우에서도  movie average 모델보다 좋은 성능 냄. 이런 상황에서도 효과적으로 도입할 수 있음을 암시함.</p>
  </li>
  <li>
    <p>넷플릭스 데이터 셋 전체 쓴 거랑 효과가 비슷함. 람다가 0.001 일때도 비슷한 rmse 효과 보이는 걸로 봐서, 일반화된 특성을 가졌다고 볼 수 있음.</p>
  </li>
  <li>
    <p>movies that were viewed but rating unknown 인 카테고리 추가하는 경우에서도 constrained PMF가 효과적임</p>
  </li>
  <li>선형적으로 PMF, PMF adaptive, constrained PMF 조합하면 0.8970 error rate 확보 가능. multiple RBM 이랑 합쳐지면 더욱 좋은 성능. 0.8861까지 발전</li>
</ul>

<h3 id="6-summary-and-discussion">6. Summary and Discussion</h3>
<ul>
  <li>PMF 개념 제시 후</li>
  <li>PMF with learnable prior</li>
  <li>
    <p>PMF with constrained situation</p>
  </li>
  <li>
    <p>training 과정에서의 효과성은 전체 사후 분포를 추정하는 것이 아닌 점 추정으로 파리미터와 하이퍼 파라미터를 구하는 과정에서 입증.</p>
  </li>
  <li>fully Bayesian method 도입하면 더욱 예측 성능 높아짐.</li>
</ul>]]></content><author><name></name></author><category term="추천시스템" /><summary type="html"><![CDATA[Mnih, Andriy, and Russ R. Salakhutdinov. “Probabilistic matrix factorization.” Advances in neural information processing systems 20 (2007): 1257-1264.]]></summary></entry><entry><title type="html">[추천시스템] Matrix Factorization Techniques for Recommender Systems</title><link href="https://sukwonyun.github.io/blog/2021/Netflix/" rel="alternate" type="text/html" title="[추천시스템] Matrix Factorization Techniques for Recommender Systems" /><published>2021-01-01T16:37:28+00:00</published><updated>2021-01-01T16:37:28+00:00</updated><id>https://sukwonyun.github.io/blog/2021/Netflix</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2021/Netflix/"><![CDATA[<p>Koren, Yehuda, Robert Bell, and Chris Volinsky. “Matrix factorization techniques for recommender systems.” Computer 42.8 (2009): 30-37.</p>

<h3 id="in-short-basic-models-of-matrix-factorizaiton"><em>In short, “Basic models of Matrix Factorizaiton”</em></h3>

<h3 id="about">About</h3>

<p>이 논문은 추천 시스템의 갈래, 그리고 Matrix Factorization 의 기초를 다루고 있는 논문으로 향 후 어떠한 모델 등으로 발전해왔는지 서술한 추천 시스템의 기본 배경지식을 잡아주는 논문이다.</p>

<h3 id="abstract">Abstract</h3>

<p>Matrix factorization 기법이 기존 nearest-neighborhood 기법보다 제품 추천에 강점을 가진다. 그 이유는 implicit feedback등을 포함할 수 있기 떄문이다.
추천시스템은 사용자의 제품에 대한 흥미 패턴을 분석해서 사용자의 입맛대로 개인화된 추천을 해주는 것이 핵심이다. 특히 엔터테인먼트, 제품, 영화, 음악 티비 쇼 등에 효과적이다.</p>

<h3 id="recommender-systems-strategies">Recommender Systems Strategies</h3>

<p>추천 시스템은 큰 틀에서 두 가지 전략으로 나뉘게 된다.</p>

<h4 id="1-content-filtering">1. Content filtering</h4>

<ul>
  <li>한 명의 유저 혹은 아이템 하나를 캐릭터화 하는 것</li>
  <li>영화 같은 경우, 장르, 배우 등</li>
  <li>사용자 같은 경우, 데모 그래픽 등</li>
  <li>외부 정보를 가져와야 하는데 쉽게 가져오기 힘든 점이 단점</li>
  <li>대표적으론 Music Genome Project</li>
</ul>

<h4 id="2-collaborative-filtering">2. Collaborative filtering</h4>

<ul>
  <li>past user behavior 바탕</li>
  <li>외부의 프로필 따로 필요없다는 장점</li>
  <li>유저간의 관계, 제품들 간의 상호의존성 분석</li>
  <li>왜? 새로운 user-item association 찾기 위해.</li>
  <li>도메인에 구속받지 않는다는 것도 큰 장점</li>
  <li>보통 content filtering 보다 정확하지만, 새로운 제품과 유저에 대해 다루지 못하는 Cold Start의 단점을 가짐.</li>
</ul>

<h5 id="2-1-neighborhood-method">2-1. Neighborhood Method</h5>

<ul>
  <li>아이템 간 혹은 유저 간의 관계 분석</li>
  <li>item-oriented: ‘같은’ 유저에 의해 평가된 다른 비슷한 아이템을 기반으로 평점 매김</li>
  <li>user-oriented: 같은 영화를 좋아한 ‘비슷한’ 유저들 바탕으로 그들이 좋아한 영화 추천</li>
  <li>user-oriendted 예시
<img src="https://user-images.githubusercontent.com/68312164/104197585-8cc53b00-5468-11eb-9b7d-cdd72dde4b94.png" width="700" height="370" /></li>
  <li>Joe 가 Star-Wars 를 좋아했다면, Star-Wars 를 역시 좋아한 Julia 가 좋아한 영화(Spider-man)를 추천</li>
</ul>

<h5 id="2-2-latent-factor-model">2-2. Latent Factor Model</h5>

<ul>
  <li>아이템과 유저들 모두 캐릭터화</li>
  <li>20-100개의 등의 팩터를 rating pattern에 의해 발굴</li>
  <li>액션을 담은 정도처럼 명확히 설명될 수도, 아니면 아예 해석이 불가능할수도 있음</li>
  <li>영화의 위치와 사용자의 위치를 내적하여 그 영화에 대한 사용자의 평점을 구함</li>
  <li>latent factor 예시
<img src="https://user-images.githubusercontent.com/68312164/104200017-7ff61680-546b-11eb-974d-560d611cacca.png" width="700" height="370" /></li>
  <li>한 축(Serious vs Escapist)이 유저와 아이템 모두를 캐릭터화하는 특징</li>
</ul>

<h5 id="2-2--matrix-factorization">2-2-*. Matrix Factorization</h5>

<ul>
  <li>Latent Factor model 의 기반이 됨</li>
  <li>평점을 매기는 패턴에 의해 아이템과 유저 모두 factor vector 로 캐릭터화</li>
  <li>적용 스케일과 높은 예측도로 많은 사랑 받음</li>
  <li>변동성 많은 현실 세계에도 잘 적합</li>
  <li>행렬을 구성할 때 사용자와, 아이템에 대한 흥미로 행렬을 나타냄</li>
  <li>가장 좋은 데이터는 사용자의 흥미를 담은 Rating과 같은 explicit feedback</li>
  <li>대부분 explicit feedback은 결측치가 많다는 단점</li>
  <li>Matrix Factorization의 또 하나의 강점은 부가적인 정보, implicit feedback 등을 담을 수 있다는 점</li>
  <li>Implicit feedback: 구매 이력, 검색 이력, 마우스 움직임 등. 보통 presence or abscence로 나타내서 밀도 있는 행렬로 볼 수 있다.</li>
</ul>

<h3 id="a-basic-matrix-factorization-model">A Basic Matrix Factorization model</h3>

<ul>
  <li>Joint Latent factor space, f 차원으로 맵핑 후 그들 사이의 상호작용은 내적으로 표현</li>
  <li>아이템 벡터: \(q_{i} \in \mathbb{R}^f\)</li>
  <li>유저 벡터: \(p_{u} \in \mathbb{R}^f\)</li>
</ul>

\[\hat{r_{ui}} = q_{i}^Tp_{u}\]

<ul>
  <li>
    <p>내적의 의미는 ‘the user’s overall interest in the item’s characteristics’</p>
  </li>
  <li>이러한 모델은 ‘SVD’ 특이값 분해와 비슷함</li>
  <li>SVD: identifying latent semantic factors in information retrieval (정보 검색에서 잠재 의미 요인 도출)</li>
  <li>Factoring the user-item rating matrix가 필요한데 rating matrix에서의 많은 결측값이 어려움을 만들어냄</li>
  <li>
    <p>적은 수의 rating 만으로 분석하기엔 오버피팅 가능성</p>
  </li>
  <li>대체값을 넣는 시도도 있었지만 모델을 왜곡시켰고, 정규화 텀을 추가해서 rating 목적식에 대한 오차제곱합을 최소화시키는 방향성 제시.</li>
</ul>

\[\min_{q^*, p^*} \sum_{(u,i)\in\mathbb{\kappa}} (r_{ui}-q_{i}^Tp_{u})^2 + \lambda(||q_{i}||^2+ ||p_{u}||^2)\]

<ul>
  <li>예측하지 못한 평점에 대해서도 잘 예측할 수 있게 만드는 일반화의 목적. 이때 정규화 텀의 람다는 cross-validation을 통해 주로 도출함</li>
</ul>

<h3 id="learning-algorithms">Learning Algorithms</h3>

<ul>
  <li>위의 오차제곱합을 줄이기 위해 SGD 방법을 통해 \(q_{i}, p_{u}\) 를 업데이트 시키는 학습 알고리즘</li>
</ul>

\[e_{ui} = r_{ui} - q_{i}^Tp_{u}\]

<ul>
  <li>ALS 기법은 두 변수 모두 모르는 상황에서 하나를 고정시키면 이차항 문제로 바뀌기 때문에 최적해를 구해낼 수 있게 됨</li>
  <li>\(q_{i}, p_{u}\) 중 하나 고정시키고 나머지 최적화시키는 방식으로 번갈아가며 수렴할 때 까지 반복</li>
  <li>시스템이 병렬적으로 운영가능한 경우와 implicit data에 집중된 경우 ALS 쓰는게 효과적일 수 있음</li>
</ul>

<h3 id="adding-biases">Adding Biases</h3>
<ul>
  <li>다양한 데이터와 실제상황에 잘 맞는 matrix factorization의 특성 활용해서 interaction이 아닌 유저, 아이템 자체의 영향력 살펴보는 방안.</li>
  <li>해리포터 자체가 다른 영화들 보다 더욱 인지도 큰 것 처럼.</li>
</ul>

\[b_{ui} = \mu + b_{i} +b_{u}\]

\[r_{ui} = \mu + b_{i} +b_{u} + q_{i}^Tp_{u}\]

\[\min_{p^*, q^*, b^*} \sum_{(u,i)\in\mathbb{\kappa}} (r_{ui}-\mu - b_{u} - b_{i} - p_{u}^Tq_{i})^2 + \lambda(||p_{u}||^2+ ||q_{i}||^2 + b_{u}^2 + b_{i}^2)\]

<ul>
  <li>이에 모델의 구성요소를 global average + item bias + user bias + user-item interaction 으로 나눌 수 있음.</li>
</ul>

<h3 id="additional-input-sources">Additional Input Sources</h3>
<ul>
  <li>많은 유저가 상당히 적은 수의 평점을 남긴 cold start 의 경우, implicit feedback 을 포함해서 해결하는 방안</li>
  <li>Normalize 도 시켜주고 implicit feedback에 대한 정보도 식에 표현시켜줌</li>
  <li>\(N_{u}\): User u 가 implicit preference를 표현한 아이템의 집합 (Boolean 고려)</li>
  <li>\(A_{u}\): User u 의 demographic과 같은 특성 (Boolean 고려)</li>
</ul>

\[r_{ui} = \mu + b_{i} +b_{u} + q_{i}^T[p_{u}+|N_{u}|^{-0.5} \sum_{i\in N_{u}}x_{i} + \sum_{a\in A_{u}}y_{a}]\]

<h3 id="temporal-dynamics">Temporal dynamics</h3>
<ul>
  <li>여태의 static한 모델들과 다르게 제품 인지도와 유명세는 시간에 따라 다르기 때문에 시간의 제약 받도록(temporal) 모델 확장</li>
  <li>Dynamic Prediction rule for a rating at a time t</li>
</ul>

\[r_{ui}(t) = \mu + b_{i}(t) +b_{u}(t) + q_{i}^Tp_{u}(t)\]

<h3 id="inputs-with-varying-confidence-levels">Inputs with Varying confidence levels</h3>
<ul>
  <li>관측된 모든 평점이 같은 가중치와 신뢰도를 갖지 않음</li>
  <li>implicit feedback 정량화 하기 힘듬</li>
  <li>이런 상황에서 confidence를 Frequency 즉, 빈도로 가져감</li>
  <li>\(c_{ui}\) 라는 confidence term 추가함</li>
</ul>

\[\min_{p^*, q^*, b^*} \sum_{(u,i)\in\mathbb{\kappa}}c_{ui}(r_{ui}-\mu - b_{u} - b_{i} - p_{u}^Tq_{i})^2 + \lambda(||p_{u}||^2+ ||q_{i}||^2 + b_{u}^2 + b_{i}^2)\]

<h3 id="netflix-prize-competition">Netflix Prize Competition</h3>
<ul>
  <li>넷플릭스가 추천 시스템 성능향상을 위해 개최한 대회</li>
  <li>RMSE를 평가척도로 사용</li>
  <li>이 논문에서 앞서 언급한 방법이 제일 효과적이었던 방법</li>
  <li>Factorizing -&gt; most descriptive dimensions for predicting movie preferences</li>
  <li>앞서 언급한 방법들을 토대로 RMSE와 파라미터 수를 축으로 plotting 해보았을 때, temporal dynamics (v.2) 가 성능 제일 좋았음. 파라미터 수 늘어날수록 RMSE도 같이 줄어듬.
<img src="https://user-images.githubusercontent.com/68312164/104260126-2f5fd700-54c6-11eb-8c6b-03fc15b123fd.png" width="700" height="370" /></li>
</ul>

<h3 id="세-줄-요약">세 줄 요약</h3>
<ol>
  <li>추천시스템은 Content filtering, Collaborative filtering으로 나뉘고 Collaborative Filtering 중 Latent Factor model을 주로 사용한다.</li>
  <li>Matrix Factorization은 기존의 Neighbor 방법보다 효과적이고 implicit feedback 등의 영향력도 모델에 포함할 수 있다.</li>
  <li>이 외에도 시간의 영향력, 신뢰도 개념까지 추가하여 더욱 정밀한 모델 설정이 가능하다.</li>
</ol>

<h4 id="references">References</h4>
<ol>
  <li>Koren, Yehuda, Robert Bell, and Chris Volinsky. “Matrix factorization techniques for recommender systems.” Computer 42.8 (2009): 30-37.</li>
</ol>]]></content><author><name></name></author><category term="추천시스템" /><category term="paper-review" /><summary type="html"><![CDATA[Koren, Yehuda, Robert Bell, and Chris Volinsky. “Matrix factorization techniques for recommender systems.” Computer 42.8 (2009): 30-37.]]></summary></entry><entry><title type="html">[추천시스템] Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</title><link href="https://sukwonyun.github.io/blog/2021/Netflix2/" rel="alternate" type="text/html" title="[추천시스템] Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model" /><published>2021-01-01T11:52:07+00:00</published><updated>2021-01-01T11:52:07+00:00</updated><id>https://sukwonyun.github.io/blog/2021/Netflix2</id><content type="html" xml:base="https://sukwonyun.github.io/blog/2021/Netflix2/"><![CDATA[<p>Koren, Yehuda. “Factorization meets the neighborhood: a multifaceted collaborative filtering model.” Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 2008.</p>

<h3 id="in-short-latent-factor-model--neighborhood-model-explicit--implicit"><em>In short, “Latent Factor model + Neighborhood model, Explicit + Implicit”</em></h3>

<h3 id="about">About</h3>
<p>이 논문은 추천시스템의 세부 영역인 Latent factor model 과 Neighborhood model을 합친 새로운 모델을 제시하고, explicit feedback 뿐만이 아닌 implicit feedback을 모델에 포함하여 성능을 높인 모델로서의 확장성을 보여준 데 큰 기여점이 있다.</p>
<h3 id="abstract">Abstract</h3>
<p>추천시스템은 주로 CF에 의존한다. 이 중, 직접적으로 사용자와 제품을 캐릭터화하는 Latent Factor Model과 사용자 간 혹은 제품 간의 유사성을 측정하는Neighborhood model 이 합쳐지는 새로운 모델을 제시한다. 확장하여, explicit, implicit 모두 사용할 수 있는 모델 제시하고, top-K-recommendation 척도로 모델 성능을 평가한다.</p>

<h3 id="1introduction">1.Introduction</h3>
<ul>
  <li>CF가 오직 과거 사용자 행동에 기반하고 새로운 explicit profile 요구하지 않는 다는 점. 도메인 지식이 필요없다는 점등 상당히 성공적으로 사용됨</li>
  <li><strong>Neighborhood</strong> 는 아이템 간 혹은 사용자 간 관계 측정에 주력</li>
  <li><strong>Latent Factor model</strong>은 SVD와 비슷해서 아이템과 사용자 모두 같은 latent facotr space에서 다룸</li>
  <li>
    <p>넷플릭스 대회에서 얻은 교훈은 neighbor, latent factor 모두 최적이라고 하기엔 무리가 있음</p>
  </li>
  <li>
    <p>Neighborhood: 근소한, local 한 관계를 잘 찾아내고 전체적인 overall한 관점에서의 평점을 잘 반영하지 못한다. 미시적</p>
  </li>
  <li>
    <p>Latent: 전체적인 구조를 잘 찾아냄. 작은 데이터 셋에서 아주 가까운 관계를 잘 못찾아냄. 거시적</p>
  </li>
  <li>
    <p>그동안에 연구에서는 두 모델을 순차적이게 사용했다는 거에 그쳤다면, 아예 통합된 새로운 모델을 제시한다는 점이 이 논문의 시사점임</p>
  </li>
  <li>
    <p>user input 을 모델에 통합시키는 것에 대한 중요성, explicit feedback은 항상 가능하지 않고, 상대적으로 풍부한 implicit feedback 많이 사용. 이 논문의 주 관점은 explicit feedback을 사용가능한 경우로 한정함. (동시에 이러한 점이 이 논문의 한계점이라고 생각함.) 이럴 때, implicit feedback을 모델에 접목시킴.</p>
  </li>
  <li>이 논문의 흐름은,
-&gt; 더욱 정확한 neighborhood 모델 제시 
-&gt; 최적화 기법에 기반 + implicit 포함
-&gt; SVD-based latent facotr 확장 + 설명력 포함
-&gt; 앞선 두 모델 병합
-&gt; top-k 평가척도로 생성한 모델 평가</li>
</ul>

<h3 id="2preliminaries">2.Preliminaries</h3>
<ul>
  <li>u,v i,j, K, 람다에 대한 기호 설명</li>
</ul>

<h4 id="21-baseline-estimates">2.1 Baseline estimates</h4>
<ul>
  <li>bui 에 대한 설정, bias 즉, baseline 역할</li>
  <li>목적식을 최소화하는 bu, bi 를 찾기 위한 텀 +
overfitting 을 막기위한 패널티 텀 추가</li>
</ul>

<h4 id="22-neighborhood-models">2.2 Neighborhood models</h4>
<ul>
  <li>기존의 방법들은 user-oriented 방법이 많았음. 이 논문의 경우, 앞으로 item-based, 즉 한명의 사용자가 평가한 비슷한 아이템 기반으로 진행될거임.</li>
  <li>무엇보다, prediction 내면의 설명력을 item-based가 더욱 높게 가져감</li>
  <li>사용자는 자기와 비슷한 사용자보다는 과거에 선호했던 아이템을 잘 알기 때문에</li>
  <li>아이템 기반에서는 item 간 similarity가 중요해짐.</li>
  <li>Pearson Correlation 기반, 더 많은 수의 유저가 평가할 수록 유사도가 높다고 판단할 수 있기에 이를 반영하여 유사도 식 도출</li>
  <li>nij = number of users rated both i and j</li>
  <li>predicted value를 neighboring item의 weighted average로 도출, 하지만 문제점으로 sustainability of similarity measure that isolates the realtions between two items (전체 이웃 셋에서 상호간 교호작용 없이), interpolation sum이 1이 된다는 건 이웃 정보가 없을 때도 이웃에 의존하게 만든다. 베이스라인에 의존하는게 합리적인 상황일 것이다.</li>
  <li>이러한 상황에서 논문은 이러한 문제점을 해결한 더욱 정확한 모델을 제시한다.  interpolation weight 으로 세타ij를 사용한다.</li>
</ul>

<h4 id="23-latent-factor-models">2.3 Latent factor models</h4>
<ul>
  <li>거시적인 관점에서 데이터를 잘 설명하는 모델이다</li>
  <li>missing 이 많은 상태에서 SVD 효과적을 적용하기 힘들고 과적합의 위험성 도래.  이를 Regularized model로 해결한다.</li>
  <li>NSVD라는 모델도 있는데 model이 실제로 평가한 item 기반한다는 차이점. 이 후 NSVD 적용할 예종</li>
</ul>

<h4 id="24-the-netflix-data">2.4 The Netflix data</h4>
<ul>
  <li>Netflix 데이터 관련 설명, RMSE 식</li>
</ul>

<h4 id="25-implicit-feedback">2.5 Implicit feedback</h4>
<ul>
  <li>Integration 을 위해, implict 개념 설명,  Ratings Matrix -&gt; Binary Matrix 관점에서 해석, 모델에 포함</li>
  <li>R(u): user u provided ratings</li>
  <li>N(u): user u provided implicit</li>
</ul>

<h3 id="3-a-neighborhood-model">3. A Neighborhood Model</h3>
<ul>
  <li>global optimzation 관점에서 새롭게 제시</li>
  <li>위에서 도출한 식이 user-specific(Sk) 기반이었으면, 이제는 한명의 user가 아닌 global 한 관점에서 user-specific weight 없애주고, wij 도입.</li>
  <li>여기서 weight 는 interpolation coefficient 가 아니라, baseline estimate의 offset으로 본다. global offset 역할을하면서 결측치에 대한 영향력을 한층 더 강조할 수 있다. 평가하지 않았다면 비슷한 영화에게 가중치 줄 수 없으니까.</li>
  <li>그리고 마찬가지로 offset 역할을 하는 implicit feedback까지 더해서 최종 모델을 완성성시킨다.</li>
  <li>
    <p>이 경우, interpolation 을 사용하지 않기에, bui를 decouple 해서 나눈다. buj는 constant. 그리고, 분해하면서 bu, bi도 wij, cij 처럼 최적화되어야 하는 parameter가 된다.</p>
  </li>
  <li>유저가 rating을  많이 제시하고, implicit feedback이 많아질수록, 즉 , R(u)와 N(u)가 모두 커지면 baseline estaimate과 갭이 커지므로 현재의 이분법적인 특성에서 좀 더 완화하여 -1/2 승 해줘서 모델 수정해준다.</li>
  <li>
    <p>i랑 비슷한 k개의 아이템 집합을 Sk(i)로 하고 각각 R(u), N(u) 와의 교집합으로 Rk(i,u), Nk(i,u) 정의하여 가장 영향력있는 가중치는 i와 비슷한 아이템일 것이다.</p>
  </li>
  <li>
    <p>new neighborhood model -&gt; facilitating an efficient global optimization procedure</p>
  </li>
  <li>Sk(i,u): u가 평가한 것들 중 i랑 가장 가까운 k개</li>
  <li>
    <p>Rk(i,u): i랑 가까운 k개중 실제로 u가 평가한 것</p>
  </li>
  <li>
    <p>Gradient Descent 를 통해 변수 업데이트 해준다.</p>
  </li>
  <li>
    <p>하이퍼 파라미터 등은 cross-validation을 통해 구하고, 이웃 사이즈 크기인 k는 k 값이 크면 클수록 항상 예측 정확도가 높았다. 이에 계산 비용과 예측 정확도 사이에 trade-off를 고려해야한다.</p>
  </li>
  <li>
    <p>이렇게 설정한 모델은 k 값이 커질수록 RMSE가 효과적으로 감소하였고 implict feedback을 제외시키면 RMSE 측면에서 효과가 감퇴함을 확인할 수 있었다.</p>
  </li>
  <li>예측은 바로 가능하지만, k 증가할수록 파라미터 예측하는데 소요시간이 그만큼 커진다.</li>
</ul>

<h3 id="4-latent-factor-models-revisited">4. Latent Factor Models Revisited</h3>
<ul>
  <li>기존의 SVD 기반의 모델에서 확장해나가는 방식</li>
  <li>implicit feedback을 접목시킨 버전</li>
  <li>그냥 user를 나타내는 vector 인 explicit parameter pu 대신에 user가 좋아하는 item 기반의 pi 사용. item 관점에서 바라보는 “Asymmetric-SVD”</li>
  <li>장점: 적은 수의 parmeter, 새로운 user에 대한 빠른 피드백(user에 대한 파라미터가 모델에 없기에), 설명도 증가, implicit feedback 에 대한 효과적인 통합</li>
  <li>역시 regularized term 추가해준 뒤 최종 ASVD 모델 구성</li>
  <li>실제로 SVD보다 더 높은 예측 정확도 가짐. implicit feedback 덕분</li>
  <li>SVD++: xj 대신에 explicit raings에 의해 학습되는 pu 벡터 사용, 위에 언급한 ASVD의 장점을 가질 수 없지만, 예측 정확도면에서는 효과적</li>
</ul>

<h3 id="5-an-integrated-model">5. An Integrated Model</h3>
<ul>
  <li>neighborhood + SVD++</li>
  <li>최종 form = general properties + iteraction between user profile and item profile + neigborhood</li>
  <li>k 높을수록 benefit 없음. 이미 latent factor model이 global 한 information 잘 표현하기 때문에
-SVD++ 와 달리, neighborhood 와 Asymmetric-SVD 는 direct 설명과 new user에 대해서 다시 re-train해야할 필요 없음</li>
  <li>설명력이 더 중요할 경우 SVD++ 대신에 Astmmetric-SVD 사용하는게 합리적</li>
</ul>

<h3 id="6-evaluation-through-a-top-k-recommender">6. Evaluation Through a Top-k-recommender</h3>
<ul>
  <li>
    <p>사용자의 만족감을 증대할 수 있는 목표가 궁극적으로 추천시스템의 목표, 그렇다면 RMSE를 10% 줄이는게 사용자 경험에 어떠한 효과를 가지는지?</p>
  </li>
  <li>
    <p>내림차순으로 정렬했을 때, 사용자에게 가장 어필이 되는 k개의 아이템 추천</p>
  </li>
</ul>

<p>-i와 1000개의 random한 영화골라서 내림차순으로 정렬한 뒤, top-k 추천.</p>
<ul>
  <li>Best: i 앞에 아무 영화도 존재 하지 않는 경우 (0%)</li>
  <li>Worse: i 앞에 모든 영화 존재하는 경우 (100%)</li>
  <li>MovieAvg &lt; CorNgbr &lt; WgtNgbr &lt; SVD &lt; Integrated
-rank가 작을수록 better recommendation, 즉 500개 중 평점 5점인 하나의 영화가 추천될 확률이 integrated model에서 높음.</li>
</ul>

<h3 id="7-conclusion">7. Conclusion</h3>
<ol>
  <li>새로운 neighborhood model 제시 (global opt 관점, 설명도, 새로운 데이터에 대한 재학습 없이)</li>
  <li>SVD-based Latent factor 모델의 확장 (implicit feedback 포함, 설명력 포함)</li>
  <li>New neighborhood model -&gt; integrated model</li>
  <li>top-K-recommender 평가척도 제시,</li>
  <li>가장 큰 인사이트 -&gt; 다양한 데이터를 다루면서 향상된 추천시스템 퀄리티 (implicit feedback 등)</li>
</ol>]]></content><author><name></name></author><category term="추천시스템" /><summary type="html"><![CDATA[Koren, Yehuda. “Factorization meets the neighborhood: a multifaceted collaborative filtering model.” Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 2008.]]></summary></entry></feed>